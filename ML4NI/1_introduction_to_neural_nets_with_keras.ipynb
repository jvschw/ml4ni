{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook 1 – Introduction to Artificial Neural Networks with Keras**\n",
    "\n",
    "_This notebook introduces ANNs._\n",
    "jens.schwarzbach@ukr.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/jvschw/blob/ml4ni/1_introduction_to_neural_nets_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advance with SHIFT ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological and artificial neurons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Artificial Neural Network (ANN) is a Machine Learning Model inspired by the networks of biological neurons found in the brain. Neurons receive input through the synapses on their dentritic branches, which leads to changes of the neuron's membrane potential. If the membrane potential falls below a certain threshold, the neuron creates an action potential, which travels down the axon and eventually reaches the synaptic terminals where the neuron makes contact with other neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ann/Blausen_0657_MultipolarNeuron_small2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronal activity is frequency encoded. This means, the more excitatory input the neuron receives the higher its firing rate (measured in spikes per second or Hz) becomes. Below, you see how the spike rate (scaled to 100%) of four neurons in primary visual cortex (V1) increases as a function of stimulus contrast [(Albrecht & Hamilton, 1982)](https://www.physiology.org/doi/abs/10.1152/jn.1982.48.1.217)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ann/CRF_Albrecht_Hamilton_1982_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This input-output dependency can be captured mathematically by a perceptron, an artificial neuron that computes the weighted sum of its inputs (input x synaptic strength) which then is passed to an activation function, which determines the output of that neuron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ann/Rosenblattperceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neurons can be equipped with a host of different activation functions. The left panel in the figure below shows some of the most common activation functions, the right panel shows their respective derivatives.\n",
    "Derivatives are important, since learning yields the strongest changes where the derivative is highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ann/activation_functions_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNs consist of different layers of (artificial) neurons, typically one input layer (red), one output layer (blue), and a variable number of hidden layers (yellow) in between. Neurons in one layer are connected to neurons in subsequent layers by means of (synaptic) weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ann/ANN_example.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating ANNs with KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we set `max_iter` and `tol` explicitly to avoid warnings about the fact that their default value will change in future versions of Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import TensorFlow and Keras.\n",
    "\n",
    "Tensorflow is a library for numerical computation developed by the Google Brain Team. In mathematics, a tensor is an algebraic object that describes a linear mapping from one set of algebraic objects (e.g.  a scalar, vector or matrix) to another. In case of ANNs this means how the activity of one neuronal layer is transformed to another layer.\n",
    "\n",
    "Keras is a high-level neural networks application programming interface (API), written in Python and capable of running on top of TensorFlow, and other libraries such as CNTK or Theano. It was developed with a focus on enabling fast experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which version is installed?\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which version is installed?\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the fashion MNIST dataset. Keras has a number of functions to load popular datasets in `keras.datasets`. \n",
    "The training data is a matrix (X) with the dimensions [nSamples, nFeatures]. The labels are contained in a vector (y) with nFeatures elements.\n",
    "The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and of 60,000 class labels, each of which being a number from 0-9: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set contains 10,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set contains 10,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and 10,000 class labels, each of which being a number from 0-9: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    " color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 6, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corresponding class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first image in the training set is a coat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pullover'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set contains 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start a keras session and initialize the random-seed generator to a fixed value such that we can replicate the session.\n",
    "Then we build a sequential model with keras. Sequential means that the information flows sequentially from one layer to the next.\n",
    "We start with an input layer, then we add two hidden layers (the first with 300 neurons, the second with 100 neurons), which are densely connected (dense means each unit of a given layer is connected to each unit to the preceding layer, as opposed to sparse connections). Both hidden layers use the relu activation function. Finally, we add an output layer with 10 neurons (because we have 10 output categories) and a softmax activation function, which gives us the probability of the class a neuron represents (all neurons sum up to a probability of 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'model.summary' provides us with a text-description of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has a function that produces a graphical depiction of a model. [Note: the ? in the numerical descriptions denotes the batch-size, which we have not defined yet. More about batch-sizes further below when we talk about the model's optimizing function.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"my_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access layers and use variables to refer to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights are initialized with small random values, otherwise there would not be any gradients and the model would be unable to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hidden layer gets its input from the input layer, which has 784 (i.e. 28x28) units. The first hidden layer itself has 300 units. We can look at the shape of the weight matrix. You see it is organized as (from, to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biases are initialized with zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each unit has its own bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to compile the model, for which we have to provide three more pieces of information: 1) the loss function (here sparse_categorical_crossentropy), 2) the optimizer for learning (here stochastic gradient descent), and 3) the performance metrics (here accuracy).\n",
    "\n",
    "Why 'sparse_categorical_crossentropy'?\n",
    "We have sparse labels (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) with nothing in between, and these labels are mutually exclusive.\n",
    "\n",
    "If we had used one-hot encoding, such as [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3, we would need to use the \"categorical_crossentropy\" loss instead.\n",
    "\n",
    "If we were doing binary classification (e.g. patient vs control) with one or more binary labels (e.g. patient vs control, male vs female),  we would use the sigmoid (i.e. logistic) activation function in the output layer instead of the \"softmax\" function, and we would use the \"binary_crossentropy\" loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set up the data and model. Now we need to tell the learning algorithm how many epochs (i.e. one loop through all training samples) to run and set the batch size.\n",
    "Stochastic Gradient Descent performs a weight update for every batch (i.e. a subset) of training data, implying there are multiple weight updates per epoch instead of going through all samples and computing one weight update per epoch. This approach leads to a faster, more stable convergence. There is a discussion about optimal batch sizes: one strategy is to make batches as large as possible such that they fit in the memory of a GPU. This strategy optimizes parallelization. But there are claims that large batch sizes lead to instable learning (which could be countered by learning-rate warmup, i.e. start with smaller learning rates, increase the learning rate for a while and later decrease it again). The alternative, and that is the approach we take here is to use a batch size of 32 samples or less.\n",
    "\n",
    "Now we are ready to fit the model (and grab a coffee)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a model provides us with a history object that contains a lot of information about the learning history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importantly, history contains a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set.\n",
    "You can create a pandas data frame from history.history and plot the learning curves below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(False)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training accuracy and the validation accuracy steadily increase during training, while the training loss and the validation loss decrease. Moreover, since the validation curves are close to the training curves, there seems to be no problem with overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point our model predicts the labels of the validation dataset with an accuracy of 87.2%. Not too bad, but is this the best we can do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=30, learning_rate=3e-3, input_shape=[28, 28]):\n",
    "    print(n_hidden, n_neurons, learning_rate)\n",
    "    model = keras.models.Sequential()   \n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    #model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_neurons=82, learning_rate=1e-05 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 82 1e-05\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 2.3181 - accuracy: 0.1583 - val_loss: 2.3058 - val_accuracy: 0.1608\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 2.2914 - accuracy: 0.1647 - val_loss: 2.2805 - val_accuracy: 0.1706\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 2.2677 - accuracy: 0.1772 - val_loss: 2.2580 - val_accuracy: 0.1858\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 2.2466 - accuracy: 0.1945 - val_loss: 2.2380 - val_accuracy: 0.2056\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 2.2280 - accuracy: 0.2138 - val_loss: 2.2203 - val_accuracy: 0.2248\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 2.2114 - accuracy: 0.2321 - val_loss: 2.2045 - val_accuracy: 0.2410\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 2.1964 - accuracy: 0.2500 - val_loss: 2.1903 - val_accuracy: 0.2570\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 70us/sample - loss: 2.1828 - accuracy: 0.2672 - val_loss: 2.1772 - val_accuracy: 0.2750\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 3s 74us/sample - loss: 2.1701 - accuracy: 0.2859 - val_loss: 2.1649 - val_accuracy: 0.2906\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 74us/sample - loss: 2.1582 - accuracy: 0.3037 - val_loss: 2.1533 - val_accuracy: 0.3084\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 2.1469 - accuracy: 0.3196 - val_loss: 2.1422 - val_accuracy: 0.3234\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 77us/sample - loss: 2.1361 - accuracy: 0.3353 - val_loss: 2.1315 - val_accuracy: 0.3392\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 2.1255 - accuracy: 0.3507 - val_loss: 2.1210 - val_accuracy: 0.3574\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 2.1151 - accuracy: 0.3660 - val_loss: 2.1107 - val_accuracy: 0.3720\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 2.1049 - accuracy: 0.3793 - val_loss: 2.1005 - val_accuracy: 0.3844\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 3s 76us/sample - loss: 2.0948 - accuracy: 0.3906 - val_loss: 2.0903 - val_accuracy: 0.3952\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 2.0847 - accuracy: 0.4011 - val_loss: 2.0803 - val_accuracy: 0.4066\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 5s 149us/sample - loss: 2.0747 - accuracy: 0.4119 - val_loss: 2.0703 - val_accuracy: 0.4170\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 2.0647 - accuracy: 0.4213 - val_loss: 2.0603 - val_accuracy: 0.4258\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 2.0547 - accuracy: 0.4311 - val_loss: 2.0504 - val_accuracy: 0.4332\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 2.0448 - accuracy: 0.4401 - val_loss: 2.0405 - val_accuracy: 0.4406\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 2.0350 - accuracy: 0.4472 - val_loss: 2.0306 - val_accuracy: 0.4466\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 3s 92us/sample - loss: 2.0252 - accuracy: 0.4542 - val_loss: 2.0208 - val_accuracy: 0.4534\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 65us/sample - loss: 2.0154 - accuracy: 0.4618 - val_loss: 2.0109 - val_accuracy: 0.4582\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 2.0057 - accuracy: 0.4676 - val_loss: 2.0011 - val_accuracy: 0.4642\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 3s 83us/sample - loss: 1.9960 - accuracy: 0.4731 - val_loss: 1.9914 - val_accuracy: 0.4708\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 1.9863 - accuracy: 0.4788 - val_loss: 1.9816 - val_accuracy: 0.4762\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 5s 140us/sample - loss: 1.9767 - accuracy: 0.4834 - val_loss: 1.9719 - val_accuracy: 0.4814\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 1.9671 - accuracy: 0.4880 - val_loss: 1.9622 - val_accuracy: 0.4884\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 3s 68us/sample - loss: 1.9575 - accuracy: 0.4924 - val_loss: 1.9525 - val_accuracy: 0.4932\n",
      "18334/18334 [==============================] - 1s 43us/sample - loss: 1.9591 - accuracy: 0.4876\n",
      "[CV] ................ n_neurons=82, learning_rate=1e-05, total= 1.8min\n",
      "[CV] n_neurons=82, learning_rate=1e-05 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 82 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 2.4688 - accuracy: 0.0991 - val_loss: 2.4597 - val_accuracy: 0.0970\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.4457 - accuracy: 0.0992 - val_loss: 2.4375 - val_accuracy: 0.0970\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 2.4244 - accuracy: 0.0993 - val_loss: 2.4168 - val_accuracy: 0.0970\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 2.4045 - accuracy: 0.0997 - val_loss: 2.3975 - val_accuracy: 0.0976\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 2.3859 - accuracy: 0.0998 - val_loss: 2.3794 - val_accuracy: 0.0980\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.3685 - accuracy: 0.1010 - val_loss: 2.3624 - val_accuracy: 0.0984\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 2.3521 - accuracy: 0.1020 - val_loss: 2.3464 - val_accuracy: 0.0992\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 2.3367 - accuracy: 0.1030 - val_loss: 2.3312 - val_accuracy: 0.1000\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 2.3221 - accuracy: 0.1048 - val_loss: 2.3170 - val_accuracy: 0.1026\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 2.3083 - accuracy: 0.1066 - val_loss: 2.3035 - val_accuracy: 0.1046\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 2.2953 - accuracy: 0.1088 - val_loss: 2.2908 - val_accuracy: 0.1074\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 2.2830 - accuracy: 0.1112 - val_loss: 2.2786 - val_accuracy: 0.1112\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 2.2712 - accuracy: 0.1137 - val_loss: 2.2671 - val_accuracy: 0.1148\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 2.2599 - accuracy: 0.1166 - val_loss: 2.2560 - val_accuracy: 0.1186\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 68us/sample - loss: 2.2490 - accuracy: 0.1202 - val_loss: 2.2453 - val_accuracy: 0.1218\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.2385 - accuracy: 0.1251 - val_loss: 2.2349 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 2.2283 - accuracy: 0.1303 - val_loss: 2.2248 - val_accuracy: 0.1304\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 2.2183 - accuracy: 0.1351 - val_loss: 2.2149 - val_accuracy: 0.1356\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 2.2086 - accuracy: 0.1402 - val_loss: 2.2052 - val_accuracy: 0.1416\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 2.1990 - accuracy: 0.1460 - val_loss: 2.1956 - val_accuracy: 0.1464\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 2.1896 - accuracy: 0.1535 - val_loss: 2.1863 - val_accuracy: 0.1546\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 2.1804 - accuracy: 0.1607 - val_loss: 2.1770 - val_accuracy: 0.1618\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.1712 - accuracy: 0.1687 - val_loss: 2.1679 - val_accuracy: 0.1694\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.1622 - accuracy: 0.1764 - val_loss: 2.1588 - val_accuracy: 0.1786\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.1532 - accuracy: 0.1865 - val_loss: 2.1498 - val_accuracy: 0.1902\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.1443 - accuracy: 0.1962 - val_loss: 2.1408 - val_accuracy: 0.2000\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.1355 - accuracy: 0.2062 - val_loss: 2.1319 - val_accuracy: 0.2108\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.1267 - accuracy: 0.2169 - val_loss: 2.1231 - val_accuracy: 0.2180\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 2.1179 - accuracy: 0.2272 - val_loss: 2.1142 - val_accuracy: 0.2258\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 2.1091 - accuracy: 0.2383 - val_loss: 2.1054 - val_accuracy: 0.2392\n",
      "18333/18333 [==============================] - 1s 43us/sample - loss: 2.1069 - accuracy: 0.2447s - loss: 2.1\n",
      "[CV] ................ n_neurons=82, learning_rate=1e-05, total= 1.5min\n",
      "[CV] n_neurons=82, learning_rate=1e-05 ...............................\n",
      "2 82 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 2.3258 - accuracy: 0.0861 - val_loss: 2.3173 - val_accuracy: 0.0826\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.3040 - accuracy: 0.0965 - val_loss: 2.2957 - val_accuracy: 0.0946\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 2.2836 - accuracy: 0.1105 - val_loss: 2.2755 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 87us/sample - loss: 2.2645 - accuracy: 0.1297 - val_loss: 2.2565 - val_accuracy: 0.1294\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.2465 - accuracy: 0.1528 - val_loss: 2.2387 - val_accuracy: 0.1514\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 86us/sample - loss: 2.2295 - accuracy: 0.1766 - val_loss: 2.2219 - val_accuracy: 0.1752\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 2.2133 - accuracy: 0.1998 - val_loss: 2.2059 - val_accuracy: 0.2038\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 2.1979 - accuracy: 0.2237 - val_loss: 2.1907 - val_accuracy: 0.2282\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.1832 - accuracy: 0.2447 - val_loss: 2.1760 - val_accuracy: 0.2474\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.1690 - accuracy: 0.2618 - val_loss: 2.1619 - val_accuracy: 0.2660\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 2.1553 - accuracy: 0.2773 - val_loss: 2.1483 - val_accuracy: 0.2866\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.1420 - accuracy: 0.2909 - val_loss: 2.1352 - val_accuracy: 0.2982\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.1291 - accuracy: 0.3045 - val_loss: 2.1223 - val_accuracy: 0.3100\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 2.1165 - accuracy: 0.3161 - val_loss: 2.1098 - val_accuracy: 0.3226\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 2.1042 - accuracy: 0.3256 - val_loss: 2.0977 - val_accuracy: 0.3312\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 2.0922 - accuracy: 0.3357 - val_loss: 2.0858 - val_accuracy: 0.3392\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.0805 - accuracy: 0.3449 - val_loss: 2.0741 - val_accuracy: 0.3492\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.0690 - accuracy: 0.3532 - val_loss: 2.0627 - val_accuracy: 0.3580\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.0578 - accuracy: 0.3623 - val_loss: 2.0514 - val_accuracy: 0.3652\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0467 - accuracy: 0.3702 - val_loss: 2.0403 - val_accuracy: 0.3768\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 2.0359 - accuracy: 0.3788 - val_loss: 2.0294 - val_accuracy: 0.3874\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 87us/sample - loss: 2.0252 - accuracy: 0.3869 - val_loss: 2.0186 - val_accuracy: 0.3964\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 87us/sample - loss: 2.0147 - accuracy: 0.3945 - val_loss: 2.0080 - val_accuracy: 0.4032\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 2.0043 - accuracy: 0.4026 - val_loss: 1.9975 - val_accuracy: 0.4132\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.9940 - accuracy: 0.4103 - val_loss: 1.9872 - val_accuracy: 0.4208\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 1.9838 - accuracy: 0.4179 - val_loss: 1.9769 - val_accuracy: 0.4300\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 1.9738 - accuracy: 0.4258 - val_loss: 1.9668 - val_accuracy: 0.4382\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 1.9638 - accuracy: 0.4339 - val_loss: 1.9568 - val_accuracy: 0.4458\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 1.9540 - accuracy: 0.4413 - val_loss: 1.9468 - val_accuracy: 0.4538\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 1.9443 - accuracy: 0.4481 - val_loss: 1.9370 - val_accuracy: 0.4614\n",
      "18333/18333 [==============================] - 1s 49us/sample - loss: 1.9341 - accuracy: 0.4607\n",
      "[CV] ................ n_neurons=82, learning_rate=1e-05, total= 1.6min\n",
      "[CV] n_neurons=147, learning_rate=1e-05 ..............................\n",
      "2 147 1e-05\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 2.3683 - accuracy: 0.1092 - val_loss: 2.3484 - val_accuracy: 0.1026\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 2.3420 - accuracy: 0.1133 - val_loss: 2.3236 - val_accuracy: 0.1050\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 2.3178 - accuracy: 0.1175 - val_loss: 2.3004 - val_accuracy: 0.1090\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 92us/sample - loss: 2.2951 - accuracy: 0.1215 - val_loss: 2.2787 - val_accuracy: 0.1138\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 2.2739 - accuracy: 0.1261 - val_loss: 2.2583 - val_accuracy: 0.1200\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 2.2539 - accuracy: 0.1330 - val_loss: 2.2391 - val_accuracy: 0.1280\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 3s 90us/sample - loss: 2.2350 - accuracy: 0.1401 - val_loss: 2.2208 - val_accuracy: 0.1386\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 2.2170 - accuracy: 0.1493 - val_loss: 2.2033 - val_accuracy: 0.1494\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 2.1999 - accuracy: 0.1611 - val_loss: 2.1866 - val_accuracy: 0.1618\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.1834 - accuracy: 0.1760 - val_loss: 2.1705 - val_accuracy: 0.1754\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 2.1676 - accuracy: 0.1944 - val_loss: 2.1550 - val_accuracy: 0.1952\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 76us/sample - loss: 2.1522 - accuracy: 0.2141 - val_loss: 2.1399 - val_accuracy: 0.2178\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 3s 77us/sample - loss: 2.1374 - accuracy: 0.2378 - val_loss: 2.1252 - val_accuracy: 0.2438\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 2.1229 - accuracy: 0.2642 - val_loss: 2.1109 - val_accuracy: 0.2738\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 3s 82us/sample - loss: 2.1087 - accuracy: 0.2909 - val_loss: 2.0969 - val_accuracy: 0.3010\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 114us/sample - loss: 2.0949 - accuracy: 0.3199 - val_loss: 2.0831 - val_accuracy: 0.3292\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 3s 77us/sample - loss: 2.0813 - accuracy: 0.3497 - val_loss: 2.0696 - val_accuracy: 0.3650\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.0680 - accuracy: 0.3761 - val_loss: 2.0564 - val_accuracy: 0.3944\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 3s 75us/sample - loss: 2.0548 - accuracy: 0.4052 - val_loss: 2.0432 - val_accuracy: 0.4216\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 3s 77us/sample - loss: 2.0419 - accuracy: 0.4285 - val_loss: 2.0303 - val_accuracy: 0.4458\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 2.0291 - accuracy: 0.4496 - val_loss: 2.0175 - val_accuracy: 0.4650\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 3s 89us/sample - loss: 2.0164 - accuracy: 0.4667 - val_loss: 2.0048 - val_accuracy: 0.4808\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 2.0039 - accuracy: 0.4816 - val_loss: 1.9923 - val_accuracy: 0.4970\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.9914 - accuracy: 0.4959 - val_loss: 1.9799 - val_accuracy: 0.5118\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 3s 85us/sample - loss: 1.9791 - accuracy: 0.5084 - val_loss: 1.9675 - val_accuracy: 0.5226\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 1.9668 - accuracy: 0.5199 - val_loss: 1.9553 - val_accuracy: 0.5332\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 1.9547 - accuracy: 0.5301 - val_loss: 1.9431 - val_accuracy: 0.5418\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.9426 - accuracy: 0.5371 - val_loss: 1.9310 - val_accuracy: 0.5492\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 3s 76us/sample - loss: 1.9306 - accuracy: 0.5447 - val_loss: 1.9190 - val_accuracy: 0.5580\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 1.9186 - accuracy: 0.5519 - val_loss: 1.9071 - val_accuracy: 0.5666\n",
      "18334/18334 [==============================] - 1s 76us/sample - loss: 1.9172 - accuracy: 0.5455\n",
      "[CV] ............... n_neurons=147, learning_rate=1e-05, total= 1.7min\n",
      "[CV] n_neurons=147, learning_rate=1e-05 ..............................\n",
      "2 147 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 114us/sample - loss: 2.3985 - accuracy: 0.0755 - val_loss: 2.3907 - val_accuracy: 0.0760\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.3683 - accuracy: 0.0821 - val_loss: 2.3618 - val_accuracy: 0.0818\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 76us/sample - loss: 2.3416 - accuracy: 0.0893 - val_loss: 2.3359 - val_accuracy: 0.0882\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 2.3176 - accuracy: 0.0968 - val_loss: 2.3123 - val_accuracy: 0.0962\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 2.2955 - accuracy: 0.1045 - val_loss: 2.2906 - val_accuracy: 0.1076\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 2.2750 - accuracy: 0.1139 - val_loss: 2.2703 - val_accuracy: 0.1192\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 2.2559 - accuracy: 0.1257 - val_loss: 2.2513 - val_accuracy: 0.1310\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.2378 - accuracy: 0.1388 - val_loss: 2.2332 - val_accuracy: 0.1494\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.2207 - accuracy: 0.1550 - val_loss: 2.2160 - val_accuracy: 0.1664\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 86us/sample - loss: 2.2042 - accuracy: 0.1729 - val_loss: 2.1995 - val_accuracy: 0.1842\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 2.1885 - accuracy: 0.1939 - val_loss: 2.1836 - val_accuracy: 0.2054\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 2.1733 - accuracy: 0.2123 - val_loss: 2.1682 - val_accuracy: 0.2284\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.1585 - accuracy: 0.2317 - val_loss: 2.1534 - val_accuracy: 0.2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 2.1442 - accuracy: 0.2494 - val_loss: 2.1389 - val_accuracy: 0.2582\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 2.1303 - accuracy: 0.2631 - val_loss: 2.1248 - val_accuracy: 0.2724\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 2.1167 - accuracy: 0.2765 - val_loss: 2.1110 - val_accuracy: 0.2848\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 2.1034 - accuracy: 0.2887 - val_loss: 2.0976 - val_accuracy: 0.2928\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 2.0904 - accuracy: 0.2987 - val_loss: 2.0844 - val_accuracy: 0.3012\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.0776 - accuracy: 0.3072 - val_loss: 2.0714 - val_accuracy: 0.3086\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 2.0651 - accuracy: 0.3150 - val_loss: 2.0587 - val_accuracy: 0.3202\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 2.0527 - accuracy: 0.3237 - val_loss: 2.0462 - val_accuracy: 0.3292\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 2.0406 - accuracy: 0.3322 - val_loss: 2.0338 - val_accuracy: 0.3368\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 2.0286 - accuracy: 0.3403 - val_loss: 2.0217 - val_accuracy: 0.3442\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 2.0168 - accuracy: 0.3481 - val_loss: 2.0097 - val_accuracy: 0.3546\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.0051 - accuracy: 0.3565 - val_loss: 1.9979 - val_accuracy: 0.3598\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.9935 - accuracy: 0.3635 - val_loss: 1.9861 - val_accuracy: 0.3704\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 1.9821 - accuracy: 0.3715 - val_loss: 1.9745 - val_accuracy: 0.3780\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.9707 - accuracy: 0.3784 - val_loss: 1.9630 - val_accuracy: 0.3870\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 1.9594 - accuracy: 0.3864 - val_loss: 1.9515 - val_accuracy: 0.3954\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.9482 - accuracy: 0.3938 - val_loss: 1.9401 - val_accuracy: 0.4030\n",
      "18333/18333 [==============================] - 1s 54us/sample - loss: 1.9443 - accuracy: 0.3971\n",
      "[CV] ............... n_neurons=147, learning_rate=1e-05, total= 1.7min\n",
      "[CV] n_neurons=147, learning_rate=1e-05 ..............................\n",
      "2 147 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 2.3396 - accuracy: 0.0860 - val_loss: 2.3317 - val_accuracy: 0.0858\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 2.3168 - accuracy: 0.0872 - val_loss: 2.3089 - val_accuracy: 0.0880\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.2952 - accuracy: 0.0905 - val_loss: 2.2873 - val_accuracy: 0.0906\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 2.2747 - accuracy: 0.0984 - val_loss: 2.2667 - val_accuracy: 0.0980\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 2.2551 - accuracy: 0.1085 - val_loss: 2.2469 - val_accuracy: 0.1092\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 2.2363 - accuracy: 0.1217 - val_loss: 2.2279 - val_accuracy: 0.1282\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 2.2181 - accuracy: 0.1396 - val_loss: 2.2096 - val_accuracy: 0.1486\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 2.2006 - accuracy: 0.1585 - val_loss: 2.1918 - val_accuracy: 0.1708\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 2.1838 - accuracy: 0.1819 - val_loss: 2.1747 - val_accuracy: 0.1946\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.1674 - accuracy: 0.2075 - val_loss: 2.1581 - val_accuracy: 0.2220\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.1516 - accuracy: 0.2342 - val_loss: 2.1420 - val_accuracy: 0.2482\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.1362 - accuracy: 0.2609 - val_loss: 2.1264 - val_accuracy: 0.2688\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 2.1212 - accuracy: 0.2855 - val_loss: 2.1112 - val_accuracy: 0.2928\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 2.1066 - accuracy: 0.3097 - val_loss: 2.0963 - val_accuracy: 0.3220\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 2.0924 - accuracy: 0.3310 - val_loss: 2.0818 - val_accuracy: 0.3448\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 85us/sample - loss: 2.0785 - accuracy: 0.3508 - val_loss: 2.0676 - val_accuracy: 0.3634\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 2.0648 - accuracy: 0.3688 - val_loss: 2.0537 - val_accuracy: 0.3806\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 2.0514 - accuracy: 0.3836 - val_loss: 2.0400 - val_accuracy: 0.3936\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 2.0383 - accuracy: 0.3974 - val_loss: 2.0266 - val_accuracy: 0.4036\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 2.0253 - accuracy: 0.4084 - val_loss: 2.0134 - val_accuracy: 0.4158\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.0126 - accuracy: 0.4187 - val_loss: 2.0003 - val_accuracy: 0.4272\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 2.0000 - accuracy: 0.4279 - val_loss: 1.9875 - val_accuracy: 0.4364\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.9876 - accuracy: 0.4370 - val_loss: 1.9748 - val_accuracy: 0.4464\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 1.9753 - accuracy: 0.4458 - val_loss: 1.9622 - val_accuracy: 0.4538\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 1.9632 - accuracy: 0.4525 - val_loss: 1.9498 - val_accuracy: 0.4632\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.9512 - accuracy: 0.4582 - val_loss: 1.9375 - val_accuracy: 0.4696\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 1.9393 - accuracy: 0.4655 - val_loss: 1.9253 - val_accuracy: 0.4762\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.9275 - accuracy: 0.4715 - val_loss: 1.9133 - val_accuracy: 0.4800\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 1.9158 - accuracy: 0.4757 - val_loss: 1.9013 - val_accuracy: 0.4840\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 1.9042 - accuracy: 0.4802 - val_loss: 1.8894 - val_accuracy: 0.4892\n",
      "18333/18333 [==============================] - 1s 42us/sample - loss: 1.8929 - accuracy: 0.4855\n",
      "[CV] ............... n_neurons=147, learning_rate=1e-05, total= 1.7min\n",
      "[CV] n_neurons=253, learning_rate=0.0001 .............................\n",
      "2 253 0.0001\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 2.2833 - accuracy: 0.1992 - val_loss: 2.1824 - val_accuracy: 0.2810\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 2.1025 - accuracy: 0.3493 - val_loss: 2.0259 - val_accuracy: 0.4302\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 1.9616 - accuracy: 0.4889 - val_loss: 1.8915 - val_accuracy: 0.5618\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 87us/sample - loss: 1.8348 - accuracy: 0.5784 - val_loss: 1.7668 - val_accuracy: 0.6114\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 88us/sample - loss: 1.7156 - accuracy: 0.6150 - val_loss: 1.6491 - val_accuracy: 0.6414\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.6030 - accuracy: 0.6353 - val_loss: 1.5392 - val_accuracy: 0.6534\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 121us/sample - loss: 1.4992 - accuracy: 0.6477 - val_loss: 1.4395 - val_accuracy: 0.6656\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.4063 - accuracy: 0.6582 - val_loss: 1.3519 - val_accuracy: 0.6720\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.3250 - accuracy: 0.6642 - val_loss: 1.2758 - val_accuracy: 0.6752\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 1.2548 - accuracy: 0.6695 - val_loss: 1.2105 - val_accuracy: 0.6786\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 1.1945 - accuracy: 0.6752 - val_loss: 1.1544 - val_accuracy: 0.6842\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 1.1427 - accuracy: 0.6794 - val_loss: 1.1062 - val_accuracy: 0.6890\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 1.0980 - accuracy: 0.6829 - val_loss: 1.0647 - val_accuracy: 0.6922\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 1.0593 - accuracy: 0.6877 - val_loss: 1.0287 - val_accuracy: 0.6974\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 1.0253 - accuracy: 0.6924 - val_loss: 0.9970 - val_accuracy: 0.7026\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.9956 - accuracy: 0.6973 - val_loss: 0.9689 - val_accuracy: 0.7070\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.9691 - accuracy: 0.7019 - val_loss: 0.9441 - val_accuracy: 0.7124\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 118us/sample - loss: 0.9455 - accuracy: 0.7063 - val_loss: 0.9219 - val_accuracy: 0.7178\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 5s 143us/sample - loss: 0.9243 - accuracy: 0.7104 - val_loss: 0.9021 - val_accuracy: 0.7218\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.9051 - accuracy: 0.7150 - val_loss: 0.8838 - val_accuracy: 0.7258\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.8876 - accuracy: 0.7189 - val_loss: 0.8672 - val_accuracy: 0.7314\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8716 - accuracy: 0.7228 - val_loss: 0.8520 - val_accuracy: 0.7372\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.8569 - accuracy: 0.7273 - val_loss: 0.8381 - val_accuracy: 0.7386\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 0.8432 - accuracy: 0.7302 - val_loss: 0.8254 - val_accuracy: 0.7410\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 7s 196us/sample - loss: 0.8306 - accuracy: 0.7334 - val_loss: 0.8132 - val_accuracy: 0.7456\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 7s 189us/sample - loss: 0.8188 - accuracy: 0.7368 - val_loss: 0.8014 - val_accuracy: 0.7494\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.8078 - accuracy: 0.7386 - val_loss: 0.7910 - val_accuracy: 0.7522\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 0.7975 - accuracy: 0.7409 - val_loss: 0.7812 - val_accuracy: 0.7522\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 0.7878 - accuracy: 0.7439 - val_loss: 0.7719 - val_accuracy: 0.7546\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 0.7786 - accuracy: 0.7464 - val_loss: 0.7630 - val_accuracy: 0.7538\n",
      "18334/18334 [==============================] - 1s 78us/sample - loss: 0.7873 - accuracy: 0.7403\n",
      "[CV] .............. n_neurons=253, learning_rate=0.0001, total= 2.2min\n",
      "[CV] n_neurons=253, learning_rate=0.0001 .............................\n",
      "2 253 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 2.2688 - accuracy: 0.1813 - val_loss: 2.1553 - val_accuracy: 0.2418\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 123us/sample - loss: 2.0732 - accuracy: 0.3203 - val_loss: 1.9897 - val_accuracy: 0.4044\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 1.9258 - accuracy: 0.4556 - val_loss: 1.8493 - val_accuracy: 0.5258\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 1.7957 - accuracy: 0.5615 - val_loss: 1.7231 - val_accuracy: 0.6010\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.6773 - accuracy: 0.6124 - val_loss: 1.6075 - val_accuracy: 0.6388\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.5682 - accuracy: 0.6347 - val_loss: 1.5016 - val_accuracy: 0.6526\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.4690 - accuracy: 0.6454 - val_loss: 1.4068 - val_accuracy: 0.6610\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.3813 - accuracy: 0.6529 - val_loss: 1.3244 - val_accuracy: 0.6668\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.3054 - accuracy: 0.6598 - val_loss: 1.2534 - val_accuracy: 0.6722\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 1.2400 - accuracy: 0.6660 - val_loss: 1.1926 - val_accuracy: 0.6760\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 117us/sample - loss: 1.1837 - accuracy: 0.6702 - val_loss: 1.1400 - val_accuracy: 0.6822\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.1350 - accuracy: 0.6754 - val_loss: 1.0948 - val_accuracy: 0.6882\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.0927 - accuracy: 0.6809 - val_loss: 1.0552 - val_accuracy: 0.6956\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.0557 - accuracy: 0.6866 - val_loss: 1.0207 - val_accuracy: 0.7000\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 1.0232 - accuracy: 0.6927 - val_loss: 0.9899 - val_accuracy: 0.7078\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 5s 127us/sample - loss: 0.9943 - accuracy: 0.6981 - val_loss: 0.9629 - val_accuracy: 0.7140\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 5s 130us/sample - loss: 0.9686 - accuracy: 0.7050 - val_loss: 0.9386 - val_accuracy: 0.7174\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.9455 - accuracy: 0.7094 - val_loss: 0.9168 - val_accuracy: 0.7250\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.9248 - accuracy: 0.7156 - val_loss: 0.8971 - val_accuracy: 0.7272\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.9059 - accuracy: 0.7197 - val_loss: 0.8794 - val_accuracy: 0.7334\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.8886 - accuracy: 0.7245 - val_loss: 0.8631 - val_accuracy: 0.7358\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.8728 - accuracy: 0.7286 - val_loss: 0.8482 - val_accuracy: 0.7420\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8582 - accuracy: 0.7328 - val_loss: 0.8342 - val_accuracy: 0.7470\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8448 - accuracy: 0.7379 - val_loss: 0.8216 - val_accuracy: 0.7480\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.8323 - accuracy: 0.7395 - val_loss: 0.8095 - val_accuracy: 0.7522\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8206 - accuracy: 0.7437 - val_loss: 0.7988 - val_accuracy: 0.7522\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.8098 - accuracy: 0.7465 - val_loss: 0.7881 - val_accuracy: 0.7582\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.7996 - accuracy: 0.7496 - val_loss: 0.7786 - val_accuracy: 0.7596\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.7900 - accuracy: 0.7521 - val_loss: 0.7689 - val_accuracy: 0.7608\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.7808 - accuracy: 0.7541 - val_loss: 0.7603 - val_accuracy: 0.7656\n",
      "18333/18333 [==============================] - 1s 56us/sample - loss: 0.7748 - accuracy: 0.7599\n",
      "[CV] .............. n_neurons=253, learning_rate=0.0001, total= 2.0min\n",
      "[CV] n_neurons=253, learning_rate=0.0001 .............................\n",
      "2 253 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 2.2480 - accuracy: 0.1576 - val_loss: 2.1572 - val_accuracy: 0.2596\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.0827 - accuracy: 0.3445 - val_loss: 2.0075 - val_accuracy: 0.4168\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.9456 - accuracy: 0.4637 - val_loss: 1.8762 - val_accuracy: 0.5164\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.8227 - accuracy: 0.5401 - val_loss: 1.7563 - val_accuracy: 0.5786\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.7095 - accuracy: 0.5856 - val_loss: 1.6455 - val_accuracy: 0.6108\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.6048 - accuracy: 0.6125 - val_loss: 1.5434 - val_accuracy: 0.6364\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.5094 - accuracy: 0.6310 - val_loss: 1.4513 - val_accuracy: 0.6490\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.4233 - accuracy: 0.6434 - val_loss: 1.3689 - val_accuracy: 0.6600\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.3464 - accuracy: 0.6544 - val_loss: 1.2960 - val_accuracy: 0.6662\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.2783 - accuracy: 0.6631 - val_loss: 1.2316 - val_accuracy: 0.6726\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.2185 - accuracy: 0.6690 - val_loss: 1.1752 - val_accuracy: 0.6792\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.1662 - accuracy: 0.6769 - val_loss: 1.1263 - val_accuracy: 0.6852\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.1206 - accuracy: 0.6815 - val_loss: 1.0834 - val_accuracy: 0.6874\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.0806 - accuracy: 0.6873 - val_loss: 1.0462 - val_accuracy: 0.6924\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.0455 - accuracy: 0.6923 - val_loss: 1.0130 - val_accuracy: 0.6952\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.0144 - accuracy: 0.6971 - val_loss: 0.9839 - val_accuracy: 0.7040\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 0.9868 - accuracy: 0.7037 - val_loss: 0.9579 - val_accuracy: 0.7080\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.9620 - accuracy: 0.7070 - val_loss: 0.9345 - val_accuracy: 0.7136\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.9399 - accuracy: 0.7130 - val_loss: 0.9136 - val_accuracy: 0.7178\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.9198 - accuracy: 0.7165 - val_loss: 0.8946 - val_accuracy: 0.7226\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.9016 - accuracy: 0.7205 - val_loss: 0.8773 - val_accuracy: 0.7262\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.8849 - accuracy: 0.7239 - val_loss: 0.8617 - val_accuracy: 0.7316\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 0.8696 - accuracy: 0.7281 - val_loss: 0.8469 - val_accuracy: 0.7352\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.8555 - accuracy: 0.7327 - val_loss: 0.8335 - val_accuracy: 0.7362\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.8423 - accuracy: 0.7352 - val_loss: 0.8210 - val_accuracy: 0.7410\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.8301 - accuracy: 0.7403 - val_loss: 0.8093 - val_accuracy: 0.7446\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8187 - accuracy: 0.7434 - val_loss: 0.7985 - val_accuracy: 0.7480\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8079 - accuracy: 0.7463 - val_loss: 0.7884 - val_accuracy: 0.7520\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.7979 - accuracy: 0.7500 - val_loss: 0.7786 - val_accuracy: 0.7526\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.7883 - accuracy: 0.7530 - val_loss: 0.7694 - val_accuracy: 0.7562\n",
      "18333/18333 [==============================] - 1s 63us/sample - loss: 0.7781 - accuracy: 0.7545\n",
      "[CV] .............. n_neurons=253, learning_rate=0.0001, total= 1.8min\n",
      "[CV] n_neurons=291, learning_rate=0.01 ...............................\n",
      "2 291 0.01\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 0.7956 - accuracy: 0.7422 - val_loss: 0.5791 - val_accuracy: 0.7968\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.5254 - accuracy: 0.8198 - val_loss: 0.4825 - val_accuracy: 0.8318\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.4732 - accuracy: 0.8371 - val_loss: 0.4469 - val_accuracy: 0.8472\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.4449 - accuracy: 0.8458 - val_loss: 0.4135 - val_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.4250 - accuracy: 0.8538 - val_loss: 0.4195 - val_accuracy: 0.8570\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.4071 - accuracy: 0.8579 - val_loss: 0.3983 - val_accuracy: 0.8648\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3927 - accuracy: 0.8631 - val_loss: 0.3896 - val_accuracy: 0.8640\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3802 - accuracy: 0.8670 - val_loss: 0.3933 - val_accuracy: 0.8654\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3701 - accuracy: 0.8707 - val_loss: 0.3678 - val_accuracy: 0.8752\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.3611 - accuracy: 0.8733 - val_loss: 0.4190 - val_accuracy: 0.8578\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3520 - accuracy: 0.8775 - val_loss: 0.3609 - val_accuracy: 0.8758\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.3447 - accuracy: 0.8784 - val_loss: 0.3812 - val_accuracy: 0.8658\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3378 - accuracy: 0.8822 - val_loss: 0.3518 - val_accuracy: 0.8722\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3291 - accuracy: 0.8843 - val_loss: 0.3747 - val_accuracy: 0.8684\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3221 - accuracy: 0.8862 - val_loss: 0.3467 - val_accuracy: 0.8820\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.3163 - accuracy: 0.8885 - val_loss: 0.3472 - val_accuracy: 0.8814\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3109 - accuracy: 0.8894 - val_loss: 0.3510 - val_accuracy: 0.8768\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3051 - accuracy: 0.8923 - val_loss: 0.3360 - val_accuracy: 0.8806\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2989 - accuracy: 0.8946 - val_loss: 0.3462 - val_accuracy: 0.8794\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.2924 - accuracy: 0.8950 - val_loss: 0.3318 - val_accuracy: 0.8846\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2896 - accuracy: 0.8972 - val_loss: 0.3218 - val_accuracy: 0.8878\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2852 - accuracy: 0.8990 - val_loss: 0.3667 - val_accuracy: 0.8712\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2802 - accuracy: 0.9009 - val_loss: 0.3379 - val_accuracy: 0.8800\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.2735 - accuracy: 0.9038 - val_loss: 0.3522 - val_accuracy: 0.8768\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.2699 - accuracy: 0.9046 - val_loss: 0.3353 - val_accuracy: 0.8794\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.2659 - accuracy: 0.9057 - val_loss: 0.3484 - val_accuracy: 0.8758\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2617 - accuracy: 0.9070 - val_loss: 0.3223 - val_accuracy: 0.8844\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.2574 - accuracy: 0.9080 - val_loss: 0.3190 - val_accuracy: 0.8864\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2519 - accuracy: 0.9104 - val_loss: 0.3561 - val_accuracy: 0.8758\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2487 - accuracy: 0.9127 - val_loss: 0.3101 - val_accuracy: 0.8916\n",
      "18334/18334 [==============================] - 1s 59us/sample - loss: 0.3249 - accuracy: 0.8814\n",
      "[CV] ................ n_neurons=291, learning_rate=0.01, total= 2.0min\n",
      "[CV] n_neurons=291, learning_rate=0.01 ...............................\n",
      "2 291 0.01\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.8118 - accuracy: 0.7397 - val_loss: 0.5573 - val_accuracy: 0.8176\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.5307 - accuracy: 0.8186 - val_loss: 0.4931 - val_accuracy: 0.8314\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.4781 - accuracy: 0.8310 - val_loss: 0.4522 - val_accuracy: 0.8492\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.4484 - accuracy: 0.8424 - val_loss: 0.4584 - val_accuracy: 0.8344\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.4261 - accuracy: 0.8510 - val_loss: 0.4053 - val_accuracy: 0.8626\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.4093 - accuracy: 0.8562 - val_loss: 0.4053 - val_accuracy: 0.8612\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3951 - accuracy: 0.8616 - val_loss: 0.3943 - val_accuracy: 0.8604\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.3836 - accuracy: 0.8663 - val_loss: 0.3871 - val_accuracy: 0.8682\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.3720 - accuracy: 0.8690 - val_loss: 0.4023 - val_accuracy: 0.8570\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.3634 - accuracy: 0.8721 - val_loss: 0.3638 - val_accuracy: 0.8708\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.3531 - accuracy: 0.8746 - val_loss: 0.3678 - val_accuracy: 0.8706\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3461 - accuracy: 0.8786 - val_loss: 0.3705 - val_accuracy: 0.8702\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.3386 - accuracy: 0.8796 - val_loss: 0.3638 - val_accuracy: 0.8748\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.3307 - accuracy: 0.8811 - val_loss: 0.3571 - val_accuracy: 0.8748\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.3246 - accuracy: 0.8838 - val_loss: 0.3507 - val_accuracy: 0.8752\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3189 - accuracy: 0.8847 - val_loss: 0.3636 - val_accuracy: 0.8714\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3123 - accuracy: 0.8881 - val_loss: 0.3472 - val_accuracy: 0.8774\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3072 - accuracy: 0.8908 - val_loss: 0.3389 - val_accuracy: 0.8804\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3005 - accuracy: 0.8911 - val_loss: 0.3419 - val_accuracy: 0.8820\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2958 - accuracy: 0.8944 - val_loss: 0.3493 - val_accuracy: 0.8754\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2899 - accuracy: 0.8954 - val_loss: 0.3340 - val_accuracy: 0.8830\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.2859 - accuracy: 0.8965 - val_loss: 0.3371 - val_accuracy: 0.8810\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.2809 - accuracy: 0.8983 - val_loss: 0.3505 - val_accuracy: 0.8734\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.2755 - accuracy: 0.9015 - val_loss: 0.3327 - val_accuracy: 0.8800\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.2711 - accuracy: 0.9017 - val_loss: 0.3265 - val_accuracy: 0.8860\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2670 - accuracy: 0.9040 - val_loss: 0.3331 - val_accuracy: 0.8800\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2624 - accuracy: 0.9062 - val_loss: 0.3195 - val_accuracy: 0.8858\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 0.2590 - accuracy: 0.9050 - val_loss: 0.3644 - val_accuracy: 0.8670\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2557 - accuracy: 0.9078 - val_loss: 0.3241 - val_accuracy: 0.8826\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2513 - accuracy: 0.9089 - val_loss: 0.3176 - val_accuracy: 0.8860\n",
      "18333/18333 [==============================] - 1s 59us/sample - loss: 0.3205 - accuracy: 0.8885\n",
      "[CV] ................ n_neurons=291, learning_rate=0.01, total= 2.1min\n",
      "[CV] n_neurons=291, learning_rate=0.01 ...............................\n",
      "2 291 0.01\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 123us/sample - loss: 0.8159 - accuracy: 0.7431 - val_loss: 0.5533 - val_accuracy: 0.8204\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.5327 - accuracy: 0.8165 - val_loss: 0.4918 - val_accuracy: 0.8336\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.4792 - accuracy: 0.8317 - val_loss: 0.4725 - val_accuracy: 0.8406\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.4492 - accuracy: 0.8433 - val_loss: 0.4266 - val_accuracy: 0.8568\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.4282 - accuracy: 0.8494 - val_loss: 0.4154 - val_accuracy: 0.8622\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.4118 - accuracy: 0.8544 - val_loss: 0.4112 - val_accuracy: 0.8590\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3960 - accuracy: 0.8620 - val_loss: 0.3972 - val_accuracy: 0.8618\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.3840 - accuracy: 0.8644 - val_loss: 0.3829 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3727 - accuracy: 0.8681 - val_loss: 0.3942 - val_accuracy: 0.8580\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3619 - accuracy: 0.8718 - val_loss: 0.3750 - val_accuracy: 0.8714\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3515 - accuracy: 0.8754 - val_loss: 0.3718 - val_accuracy: 0.8704\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.3453 - accuracy: 0.8765 - val_loss: 0.3842 - val_accuracy: 0.8670\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3364 - accuracy: 0.8804 - val_loss: 0.3583 - val_accuracy: 0.8746\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3286 - accuracy: 0.8837 - val_loss: 0.3616 - val_accuracy: 0.8738\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3227 - accuracy: 0.8846 - val_loss: 0.3505 - val_accuracy: 0.8796\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3159 - accuracy: 0.8869 - val_loss: 0.3642 - val_accuracy: 0.8742\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3108 - accuracy: 0.8882 - val_loss: 0.3509 - val_accuracy: 0.8778\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.3037 - accuracy: 0.8912 - val_loss: 0.3433 - val_accuracy: 0.8810\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.2978 - accuracy: 0.8936 - val_loss: 0.3408 - val_accuracy: 0.8784\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.2936 - accuracy: 0.8949 - val_loss: 0.3338 - val_accuracy: 0.8808\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.2874 - accuracy: 0.8955 - val_loss: 0.3324 - val_accuracy: 0.8834\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2831 - accuracy: 0.8981 - val_loss: 0.3387 - val_accuracy: 0.8818\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2774 - accuracy: 0.9002 - val_loss: 0.3307 - val_accuracy: 0.8828\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.2743 - accuracy: 0.9020 - val_loss: 0.3209 - val_accuracy: 0.8862\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2679 - accuracy: 0.9048 - val_loss: 0.3318 - val_accuracy: 0.8798\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2648 - accuracy: 0.9056 - val_loss: 0.3267 - val_accuracy: 0.8804\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2594 - accuracy: 0.9060 - val_loss: 0.3442 - val_accuracy: 0.8794\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2567 - accuracy: 0.9074 - val_loss: 0.3393 - val_accuracy: 0.8740\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.2509 - accuracy: 0.9107 - val_loss: 0.3246 - val_accuracy: 0.8840\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2474 - accuracy: 0.9121 - val_loss: 0.3274 - val_accuracy: 0.8838\n",
      "18333/18333 [==============================] - 1s 58us/sample - loss: 0.3353 - accuracy: 0.8821\n",
      "[CV] ................ n_neurons=291, learning_rate=0.01, total= 2.0min\n",
      "[CV] n_neurons=212, learning_rate=0.0001 .............................\n",
      "2 212 0.0001\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 2.2482 - accuracy: 0.2007 - val_loss: 2.1291 - val_accuracy: 0.2540\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 2.0451 - accuracy: 0.3400 - val_loss: 1.9726 - val_accuracy: 0.3924\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 1.9094 - accuracy: 0.4488 - val_loss: 1.8470 - val_accuracy: 0.4998\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.7932 - accuracy: 0.5407 - val_loss: 1.7343 - val_accuracy: 0.5818\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 1.6875 - accuracy: 0.5976 - val_loss: 1.6307 - val_accuracy: 0.6246\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.5901 - accuracy: 0.6262 - val_loss: 1.5356 - val_accuracy: 0.6456\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.5011 - accuracy: 0.6409 - val_loss: 1.4495 - val_accuracy: 0.6570\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.4208 - accuracy: 0.6509 - val_loss: 1.3726 - val_accuracy: 0.6632\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.3492 - accuracy: 0.6567 - val_loss: 1.3044 - val_accuracy: 0.6674\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 1.2857 - accuracy: 0.6617 - val_loss: 1.2446 - val_accuracy: 0.6714\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 1.2297 - accuracy: 0.6665 - val_loss: 1.1917 - val_accuracy: 0.6742\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 1.1804 - accuracy: 0.6711 - val_loss: 1.1453 - val_accuracy: 0.6782\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 1.1369 - accuracy: 0.6757 - val_loss: 1.1046 - val_accuracy: 0.6854\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 1.0985 - accuracy: 0.6801 - val_loss: 1.0686 - val_accuracy: 0.6910\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 1.0644 - accuracy: 0.6846 - val_loss: 1.0366 - val_accuracy: 0.6960\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 1.0341 - accuracy: 0.6887 - val_loss: 1.0079 - val_accuracy: 0.7020\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 1.0068 - accuracy: 0.6938 - val_loss: 0.9821 - val_accuracy: 0.7042\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 0.9822 - accuracy: 0.6981 - val_loss: 0.9590 - val_accuracy: 0.7086\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 0.9600 - accuracy: 0.7031 - val_loss: 0.9381 - val_accuracy: 0.7144\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 0.9397 - accuracy: 0.7076 - val_loss: 0.9187 - val_accuracy: 0.7190\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 0.9211 - accuracy: 0.7115 - val_loss: 0.9010 - val_accuracy: 0.7218\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 0.9039 - accuracy: 0.7159 - val_loss: 0.8849 - val_accuracy: 0.7270\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 0.8881 - accuracy: 0.7199 - val_loss: 0.8699 - val_accuracy: 0.7292\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 0.8734 - accuracy: 0.7232 - val_loss: 0.8561 - val_accuracy: 0.7328\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 3s 92us/sample - loss: 0.8598 - accuracy: 0.7264 - val_loss: 0.8430 - val_accuracy: 0.7342\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 0.8471 - accuracy: 0.7303 - val_loss: 0.8306 - val_accuracy: 0.7412\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 0.8353 - accuracy: 0.7328 - val_loss: 0.8194 - val_accuracy: 0.7470\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 0.8241 - accuracy: 0.7362 - val_loss: 0.8088 - val_accuracy: 0.7508\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 0.8136 - accuracy: 0.7395 - val_loss: 0.7987 - val_accuracy: 0.7518\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 3s 93us/sample - loss: 0.8037 - accuracy: 0.7421 - val_loss: 0.7892 - val_accuracy: 0.7548\n",
      "18334/18334 [==============================] - 1s 52us/sample - loss: 0.8130 - accuracy: 0.7373\n",
      "[CV] .............. n_neurons=212, learning_rate=0.0001, total= 1.8min\n",
      "[CV] n_neurons=212, learning_rate=0.0001 .............................\n",
      "2 212 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 2.2685 - accuracy: 0.1212 - val_loss: 2.1715 - val_accuracy: 0.2332\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 2.0984 - accuracy: 0.3298 - val_loss: 2.0212 - val_accuracy: 0.4214\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 1.9590 - accuracy: 0.4761 - val_loss: 1.8867 - val_accuracy: 0.5354\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 1.8308 - accuracy: 0.5626 - val_loss: 1.7601 - val_accuracy: 0.6060\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 1.7104 - accuracy: 0.6094 - val_loss: 1.6416 - val_accuracy: 0.6448\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.5995 - accuracy: 0.6339 - val_loss: 1.5342 - val_accuracy: 0.6590\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.4998 - accuracy: 0.6474 - val_loss: 1.4386 - val_accuracy: 0.6680\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.4114 - accuracy: 0.6544 - val_loss: 1.3547 - val_accuracy: 0.6716\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 5s 129us/sample - loss: 1.3341 - accuracy: 0.6592 - val_loss: 1.2819 - val_accuracy: 0.6748\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 1.2671 - accuracy: 0.6635 - val_loss: 1.2193 - val_accuracy: 0.6770\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 8s 224us/sample - loss: 1.2092 - accuracy: 0.6662 - val_loss: 1.1650 - val_accuracy: 0.6812\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 1.1590 - accuracy: 0.6698 - val_loss: 1.1183 - val_accuracy: 0.6828\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 1.1154 - accuracy: 0.6729 - val_loss: 1.0775 - val_accuracy: 0.6894\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 1.0772 - accuracy: 0.6775 - val_loss: 1.0419 - val_accuracy: 0.6914\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 1.0437 - accuracy: 0.6818 - val_loss: 1.0102 - val_accuracy: 0.6980\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 1.0140 - accuracy: 0.6865 - val_loss: 0.9823 - val_accuracy: 0.7048\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.9875 - accuracy: 0.6929 - val_loss: 0.9572 - val_accuracy: 0.7090\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.9638 - accuracy: 0.6975 - val_loss: 0.9348 - val_accuracy: 0.7158\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.9424 - accuracy: 0.7035 - val_loss: 0.9144 - val_accuracy: 0.7188\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.9230 - accuracy: 0.7071 - val_loss: 0.8962 - val_accuracy: 0.7250\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 0.9053 - accuracy: 0.7116 - val_loss: 0.8792 - val_accuracy: 0.7284\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 0.8891 - accuracy: 0.7158 - val_loss: 0.8640 - val_accuracy: 0.7332\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 0.8741 - accuracy: 0.7196 - val_loss: 0.8493 - val_accuracy: 0.7384\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.8603 - accuracy: 0.7242 - val_loss: 0.8362 - val_accuracy: 0.7398\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 0.8475 - accuracy: 0.7267 - val_loss: 0.8238 - val_accuracy: 0.7428\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8354 - accuracy: 0.7311 - val_loss: 0.8127 - val_accuracy: 0.7480\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 0.8243 - accuracy: 0.7346 - val_loss: 0.8017 - val_accuracy: 0.7496\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 0.8137 - accuracy: 0.7367 - val_loss: 0.7918 - val_accuracy: 0.7532\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8039 - accuracy: 0.7409 - val_loss: 0.7819 - val_accuracy: 0.7548\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.7945 - accuracy: 0.7427 - val_loss: 0.7731 - val_accuracy: 0.7574\n",
      "18333/18333 [==============================] - 1s 65us/sample - loss: 0.7886 - accuracy: 0.7459\n",
      "[CV] .............. n_neurons=212, learning_rate=0.0001, total= 2.1min\n",
      "[CV] n_neurons=212, learning_rate=0.0001 .............................\n",
      "2 212 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 2.2067 - accuracy: 0.1832 - val_loss: 2.1304 - val_accuracy: 0.2628\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 2.0593 - accuracy: 0.3649 - val_loss: 1.9926 - val_accuracy: 0.4472\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.9315 - accuracy: 0.4939 - val_loss: 1.8691 - val_accuracy: 0.5350\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.8151 - accuracy: 0.5610 - val_loss: 1.7552 - val_accuracy: 0.5954\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.7072 - accuracy: 0.6066 - val_loss: 1.6492 - val_accuracy: 0.6302\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.6069 - accuracy: 0.6292 - val_loss: 1.5505 - val_accuracy: 0.6444\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.5141 - accuracy: 0.6433 - val_loss: 1.4598 - val_accuracy: 0.6554\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.4293 - accuracy: 0.6527 - val_loss: 1.3773 - val_accuracy: 0.6638\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.3527 - accuracy: 0.6607 - val_loss: 1.3036 - val_accuracy: 0.6706\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.2843 - accuracy: 0.6671 - val_loss: 1.2381 - val_accuracy: 0.6782\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.2238 - accuracy: 0.6731 - val_loss: 1.1805 - val_accuracy: 0.6860\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.1705 - accuracy: 0.6786 - val_loss: 1.1303 - val_accuracy: 0.6910\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.1237 - accuracy: 0.6845 - val_loss: 1.0859 - val_accuracy: 0.6982\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.0826 - accuracy: 0.6891 - val_loss: 1.0475 - val_accuracy: 0.7030\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.0465 - accuracy: 0.6935 - val_loss: 1.0131 - val_accuracy: 0.7096\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.0147 - accuracy: 0.6995 - val_loss: 0.9834 - val_accuracy: 0.7130\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.9865 - accuracy: 0.7049 - val_loss: 0.9565 - val_accuracy: 0.7156\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.9613 - accuracy: 0.7078 - val_loss: 0.9326 - val_accuracy: 0.7172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 0.9387 - accuracy: 0.7120 - val_loss: 0.9112 - val_accuracy: 0.7214\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.9184 - accuracy: 0.7159 - val_loss: 0.8918 - val_accuracy: 0.7232\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8999 - accuracy: 0.7207 - val_loss: 0.8742 - val_accuracy: 0.7272\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 116us/sample - loss: 0.8830 - accuracy: 0.7227 - val_loss: 0.8582 - val_accuracy: 0.7310\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.8674 - accuracy: 0.7263 - val_loss: 0.8431 - val_accuracy: 0.7342\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8532 - accuracy: 0.7289 - val_loss: 0.8296 - val_accuracy: 0.7384\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.8401 - accuracy: 0.7313 - val_loss: 0.8172 - val_accuracy: 0.7416\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8281 - accuracy: 0.7342 - val_loss: 0.8057 - val_accuracy: 0.7448\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8170 - accuracy: 0.7372 - val_loss: 0.7951 - val_accuracy: 0.7476\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 0.8066 - accuracy: 0.7392 - val_loss: 0.7854 - val_accuracy: 0.7508\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.7970 - accuracy: 0.7425 - val_loss: 0.7759 - val_accuracy: 0.7538\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.7879 - accuracy: 0.7450 - val_loss: 0.7670 - val_accuracy: 0.7554\n",
      "18333/18333 [==============================] - 1s 54us/sample - loss: 0.7769 - accuracy: 0.7470\n",
      "[CV] .............. n_neurons=212, learning_rate=0.0001, total= 1.8min\n",
      "[CV] n_neurons=247, learning_rate=1e-05 ..............................\n",
      "2 247 1e-05\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 2.3459 - accuracy: 0.0500 - val_loss: 2.3373 - val_accuracy: 0.0532\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.3233 - accuracy: 0.0668 - val_loss: 2.3150 - val_accuracy: 0.0714\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 2.3015 - accuracy: 0.0889 - val_loss: 2.2933 - val_accuracy: 0.0950\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.2805 - accuracy: 0.1166 - val_loss: 2.2724 - val_accuracy: 0.1232\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.2601 - accuracy: 0.1426 - val_loss: 2.2521 - val_accuracy: 0.1496\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.2404 - accuracy: 0.1681 - val_loss: 2.2324 - val_accuracy: 0.1804\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 2.2212 - accuracy: 0.1936 - val_loss: 2.2133 - val_accuracy: 0.2042\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 2.2025 - accuracy: 0.2156 - val_loss: 2.1946 - val_accuracy: 0.2292\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 2.1843 - accuracy: 0.2360 - val_loss: 2.1764 - val_accuracy: 0.2486\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.1665 - accuracy: 0.2526 - val_loss: 2.1586 - val_accuracy: 0.2638\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.1491 - accuracy: 0.2682 - val_loss: 2.1411 - val_accuracy: 0.2776\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 2.1320 - accuracy: 0.2832 - val_loss: 2.1239 - val_accuracy: 0.2922\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 2.1152 - accuracy: 0.2977 - val_loss: 2.1071 - val_accuracy: 0.3060\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 2.0987 - accuracy: 0.3134 - val_loss: 2.0905 - val_accuracy: 0.3212\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 2.0824 - accuracy: 0.3293 - val_loss: 2.0741 - val_accuracy: 0.3374\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.0664 - accuracy: 0.3435 - val_loss: 2.0580 - val_accuracy: 0.3500\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 2.0506 - accuracy: 0.3566 - val_loss: 2.0420 - val_accuracy: 0.3632\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.0349 - accuracy: 0.3706 - val_loss: 2.0263 - val_accuracy: 0.3794\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 2.0195 - accuracy: 0.3843 - val_loss: 2.0107 - val_accuracy: 0.3912\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 2.0042 - accuracy: 0.3982 - val_loss: 1.9952 - val_accuracy: 0.4024\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 1.9891 - accuracy: 0.4108 - val_loss: 1.9800 - val_accuracy: 0.4138\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 1.9741 - accuracy: 0.4231 - val_loss: 1.9648 - val_accuracy: 0.4268\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 1.9593 - accuracy: 0.4360 - val_loss: 1.9498 - val_accuracy: 0.4426\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 4s 98us/sample - loss: 1.9446 - accuracy: 0.4489 - val_loss: 1.9350 - val_accuracy: 0.4530\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 1.9301 - accuracy: 0.4619 - val_loss: 1.9204 - val_accuracy: 0.4662\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 1.9157 - accuracy: 0.4747 - val_loss: 1.9058 - val_accuracy: 0.4796\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 99us/sample - loss: 1.9015 - accuracy: 0.4858 - val_loss: 1.8915 - val_accuracy: 0.4910\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 1.8874 - accuracy: 0.4980 - val_loss: 1.8773 - val_accuracy: 0.5020\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 1.8735 - accuracy: 0.5110 - val_loss: 1.8633 - val_accuracy: 0.5146\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 4s 100us/sample - loss: 1.8597 - accuracy: 0.5203 - val_loss: 1.8494 - val_accuracy: 0.5244\n",
      "18334/18334 [==============================] - 1s 54us/sample - loss: 1.8598 - accuracy: 0.5130\n",
      "[CV] ............... n_neurons=247, learning_rate=1e-05, total= 1.8min\n",
      "[CV] n_neurons=247, learning_rate=1e-05 ..............................\n",
      "2 247 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 2.3198 - accuracy: 0.0777 - val_loss: 2.3113 - val_accuracy: 0.0762\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.2960 - accuracy: 0.0788 - val_loss: 2.2880 - val_accuracy: 0.0772\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.2738 - accuracy: 0.0812 - val_loss: 2.2661 - val_accuracy: 0.0790\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 95us/sample - loss: 2.2530 - accuracy: 0.0841 - val_loss: 2.2455 - val_accuracy: 0.0842\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.2333 - accuracy: 0.0883 - val_loss: 2.2259 - val_accuracy: 0.0888\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.2146 - accuracy: 0.0943 - val_loss: 2.2072 - val_accuracy: 0.0930\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.1966 - accuracy: 0.1018 - val_loss: 2.1892 - val_accuracy: 0.1026\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 2.1793 - accuracy: 0.1114 - val_loss: 2.1718 - val_accuracy: 0.1118\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.1626 - accuracy: 0.1230 - val_loss: 2.1549 - val_accuracy: 0.1252\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.1463 - accuracy: 0.1377 - val_loss: 2.1385 - val_accuracy: 0.1396\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.1305 - accuracy: 0.1535 - val_loss: 2.1224 - val_accuracy: 0.1574\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.1149 - accuracy: 0.1740 - val_loss: 2.1066 - val_accuracy: 0.1820\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.0997 - accuracy: 0.1988 - val_loss: 2.0912 - val_accuracy: 0.2096\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.0848 - accuracy: 0.2263 - val_loss: 2.0760 - val_accuracy: 0.2386\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.0701 - accuracy: 0.2542 - val_loss: 2.0610 - val_accuracy: 0.2658\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 2.0556 - accuracy: 0.2789 - val_loss: 2.0462 - val_accuracy: 0.2948\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.0412 - accuracy: 0.3023 - val_loss: 2.0317 - val_accuracy: 0.3154\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.0271 - accuracy: 0.3236 - val_loss: 2.0173 - val_accuracy: 0.3388\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0131 - accuracy: 0.3437 - val_loss: 2.0030 - val_accuracy: 0.3576\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9992 - accuracy: 0.3626 - val_loss: 1.9889 - val_accuracy: 0.3774\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9855 - accuracy: 0.3790 - val_loss: 1.9750 - val_accuracy: 0.3910\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.9719 - accuracy: 0.3964 - val_loss: 1.9611 - val_accuracy: 0.4114\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9584 - accuracy: 0.4135 - val_loss: 1.9474 - val_accuracy: 0.4284\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9450 - accuracy: 0.4290 - val_loss: 1.9338 - val_accuracy: 0.4460\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9317 - accuracy: 0.4438 - val_loss: 1.9203 - val_accuracy: 0.4590\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9185 - accuracy: 0.4572 - val_loss: 1.9068 - val_accuracy: 0.4692\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9054 - accuracy: 0.4688 - val_loss: 1.8935 - val_accuracy: 0.4826\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.8923 - accuracy: 0.4799 - val_loss: 1.8803 - val_accuracy: 0.4932\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.8794 - accuracy: 0.4895 - val_loss: 1.8671 - val_accuracy: 0.5046\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.8666 - accuracy: 0.4995 - val_loss: 1.8541 - val_accuracy: 0.5144\n",
      "18333/18333 [==============================] - 1s 57us/sample - loss: 1.8617 - accuracy: 0.5046s - loss: 1.8615 - accura\n",
      "[CV] ............... n_neurons=247, learning_rate=1e-05, total= 1.8min\n",
      "[CV] n_neurons=247, learning_rate=1e-05 ..............................\n",
      "2 247 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 2.2824 - accuracy: 0.1060 - val_loss: 2.2755 - val_accuracy: 0.1062\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.2638 - accuracy: 0.1103 - val_loss: 2.2565 - val_accuracy: 0.1130\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.2457 - accuracy: 0.1172 - val_loss: 2.2380 - val_accuracy: 0.1202\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.2282 - accuracy: 0.1235 - val_loss: 2.2201 - val_accuracy: 0.1264\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.2111 - accuracy: 0.1306 - val_loss: 2.2027 - val_accuracy: 0.1340\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.1945 - accuracy: 0.1393 - val_loss: 2.1856 - val_accuracy: 0.1446\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.1782 - accuracy: 0.1496 - val_loss: 2.1689 - val_accuracy: 0.1570\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 2.1622 - accuracy: 0.1615 - val_loss: 2.1525 - val_accuracy: 0.1694\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 2.1465 - accuracy: 0.1769 - val_loss: 2.1364 - val_accuracy: 0.1844\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 2.1311 - accuracy: 0.1934 - val_loss: 2.1206 - val_accuracy: 0.2040\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.1160 - accuracy: 0.2098 - val_loss: 2.1050 - val_accuracy: 0.2220\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.1011 - accuracy: 0.2285 - val_loss: 2.0896 - val_accuracy: 0.2414\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0863 - accuracy: 0.2465 - val_loss: 2.0745 - val_accuracy: 0.2626\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.0717 - accuracy: 0.2676 - val_loss: 2.0595 - val_accuracy: 0.2860\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.0573 - accuracy: 0.2886 - val_loss: 2.0447 - val_accuracy: 0.3090\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.0429 - accuracy: 0.3116 - val_loss: 2.0300 - val_accuracy: 0.3322\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0287 - accuracy: 0.3325 - val_loss: 2.0154 - val_accuracy: 0.3518\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 2.0146 - accuracy: 0.3521 - val_loss: 2.0010 - val_accuracy: 0.3670\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0006 - accuracy: 0.3693 - val_loss: 1.9866 - val_accuracy: 0.3854\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.9867 - accuracy: 0.3831 - val_loss: 1.9724 - val_accuracy: 0.3998\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.9729 - accuracy: 0.3979 - val_loss: 1.9583 - val_accuracy: 0.4146\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.9591 - accuracy: 0.4105 - val_loss: 1.9442 - val_accuracy: 0.4302\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.9454 - accuracy: 0.4225 - val_loss: 1.9302 - val_accuracy: 0.4424\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.9318 - accuracy: 0.4337 - val_loss: 1.9164 - val_accuracy: 0.4556\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.9183 - accuracy: 0.4447 - val_loss: 1.9026 - val_accuracy: 0.4628\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.9049 - accuracy: 0.4559 - val_loss: 1.8888 - val_accuracy: 0.4748\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.8915 - accuracy: 0.4653 - val_loss: 1.8752 - val_accuracy: 0.4828\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.8783 - accuracy: 0.4760 - val_loss: 1.8617 - val_accuracy: 0.4918\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.8651 - accuracy: 0.4853 - val_loss: 1.8483 - val_accuracy: 0.5030\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.8520 - accuracy: 0.4962 - val_loss: 1.8350 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18333/18333 [==============================] - 1s 54us/sample - loss: 1.8409 - accuracy: 0.5039\n",
      "[CV] ............... n_neurons=247, learning_rate=1e-05, total= 1.9min\n",
      "[CV] n_neurons=241, learning_rate=1e-05 ..............................\n",
      "2 241 1e-05\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 2.3298 - accuracy: 0.2263 - val_loss: 2.3204 - val_accuracy: 0.2266\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 96us/sample - loss: 2.2980 - accuracy: 0.2418 - val_loss: 2.2897 - val_accuracy: 0.2400\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 2.2688 - accuracy: 0.2567 - val_loss: 2.2613 - val_accuracy: 0.2570\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 2.2419 - accuracy: 0.2735 - val_loss: 2.2351 - val_accuracy: 0.2718\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 2.2169 - accuracy: 0.2889 - val_loss: 2.2107 - val_accuracy: 0.2902\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 95us/sample - loss: 2.1936 - accuracy: 0.3042 - val_loss: 2.1878 - val_accuracy: 0.3048\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 97us/sample - loss: 2.1717 - accuracy: 0.3176 - val_loss: 2.1663 - val_accuracy: 0.3176\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 2.1511 - accuracy: 0.3314 - val_loss: 2.1460 - val_accuracy: 0.3324\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 2.1316 - accuracy: 0.3448 - val_loss: 2.1267 - val_accuracy: 0.3464\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 7s 193us/sample - loss: 2.1130 - accuracy: 0.3586 - val_loss: 2.1082 - val_accuracy: 0.3596\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 5s 125us/sample - loss: 2.0952 - accuracy: 0.3720 - val_loss: 2.0905 - val_accuracy: 0.3728\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 5s 147us/sample - loss: 2.0781 - accuracy: 0.3850 - val_loss: 2.0735 - val_accuracy: 0.3874\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 8s 213us/sample - loss: 2.0616 - accuracy: 0.3973 - val_loss: 2.0570 - val_accuracy: 0.3978\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 7s 189us/sample - loss: 2.0456 - accuracy: 0.4090 - val_loss: 2.0410 - val_accuracy: 0.4120\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 2.0301 - accuracy: 0.4197 - val_loss: 2.0254 - val_accuracy: 0.4218\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 8s 217us/sample - loss: 2.0149 - accuracy: 0.4298 - val_loss: 2.0102 - val_accuracy: 0.4324\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 9s 247us/sample - loss: 2.0001 - accuracy: 0.4382 - val_loss: 1.9953 - val_accuracy: 0.4428\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 1.9856 - accuracy: 0.4462 - val_loss: 1.9806 - val_accuracy: 0.4522\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 1.9713 - accuracy: 0.4558 - val_loss: 1.9662 - val_accuracy: 0.4608\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 1.9573 - accuracy: 0.4641 - val_loss: 1.9520 - val_accuracy: 0.4684\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 1.9435 - accuracy: 0.4728 - val_loss: 1.9380 - val_accuracy: 0.4766\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 1.9299 - accuracy: 0.4812 - val_loss: 1.9243 - val_accuracy: 0.4886\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 1.9165 - accuracy: 0.4902 - val_loss: 1.9106 - val_accuracy: 0.4972\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 1.9032 - accuracy: 0.4989 - val_loss: 1.8971 - val_accuracy: 0.5046\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 1.8900 - accuracy: 0.5065 - val_loss: 1.8837 - val_accuracy: 0.5114\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 1.8770 - accuracy: 0.5150 - val_loss: 1.8704 - val_accuracy: 0.5202\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 114us/sample - loss: 1.8641 - accuracy: 0.5227 - val_loss: 1.8572 - val_accuracy: 0.5294\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 1.8512 - accuracy: 0.5300 - val_loss: 1.8441 - val_accuracy: 0.5362\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 4s 122us/sample - loss: 1.8385 - accuracy: 0.5371 - val_loss: 1.8311 - val_accuracy: 0.5422\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 5s 126us/sample - loss: 1.8258 - accuracy: 0.5431 - val_loss: 1.8183 - val_accuracy: 0.5474\n",
      "18334/18334 [==============================] - 1s 68us/sample - loss: 1.8256 - accuracy: 0.5356\n",
      "[CV] ............... n_neurons=241, learning_rate=1e-05, total= 2.5min\n",
      "[CV] n_neurons=241, learning_rate=1e-05 ..............................\n",
      "2 241 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 2.4181 - accuracy: 0.0598 - val_loss: 2.3907 - val_accuracy: 0.0732\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 2.3789 - accuracy: 0.0812 - val_loss: 2.3543 - val_accuracy: 0.0940\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 2.3439 - accuracy: 0.0993 - val_loss: 2.3215 - val_accuracy: 0.1142\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 2.3124 - accuracy: 0.1135 - val_loss: 2.2917 - val_accuracy: 0.1302\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.2836 - accuracy: 0.1260 - val_loss: 2.2642 - val_accuracy: 0.1414\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.2570 - accuracy: 0.1389 - val_loss: 2.2386 - val_accuracy: 0.1570\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.2322 - accuracy: 0.1541 - val_loss: 2.2146 - val_accuracy: 0.1702\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.2089 - accuracy: 0.1709 - val_loss: 2.1919 - val_accuracy: 0.1888\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.1867 - accuracy: 0.1901 - val_loss: 2.1703 - val_accuracy: 0.2038\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.1655 - accuracy: 0.2108 - val_loss: 2.1495 - val_accuracy: 0.2256\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.1452 - accuracy: 0.2328 - val_loss: 2.1295 - val_accuracy: 0.2466\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.1255 - accuracy: 0.2527 - val_loss: 2.1101 - val_accuracy: 0.2628\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.1065 - accuracy: 0.2707 - val_loss: 2.0912 - val_accuracy: 0.2820\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.0880 - accuracy: 0.2876 - val_loss: 2.0728 - val_accuracy: 0.2970\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 2.0700 - accuracy: 0.3023 - val_loss: 2.0548 - val_accuracy: 0.3124\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0523 - accuracy: 0.3148 - val_loss: 2.0371 - val_accuracy: 0.3236\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 2.0350 - accuracy: 0.3254 - val_loss: 2.0197 - val_accuracy: 0.3374\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.0180 - accuracy: 0.3359 - val_loss: 2.0027 - val_accuracy: 0.3482\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 2.0013 - accuracy: 0.3458 - val_loss: 1.9859 - val_accuracy: 0.3570\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.9848 - accuracy: 0.3556 - val_loss: 1.9693 - val_accuracy: 0.3680\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.9686 - accuracy: 0.3661 - val_loss: 1.9530 - val_accuracy: 0.3770\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 1.9526 - accuracy: 0.3760 - val_loss: 1.9370 - val_accuracy: 0.3862\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.9369 - accuracy: 0.3854 - val_loss: 1.9211 - val_accuracy: 0.3958\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.9214 - accuracy: 0.3949 - val_loss: 1.9055 - val_accuracy: 0.4064\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 1.9062 - accuracy: 0.4047 - val_loss: 1.8901 - val_accuracy: 0.4162\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.8911 - accuracy: 0.4133 - val_loss: 1.8749 - val_accuracy: 0.4244\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.8763 - accuracy: 0.4226 - val_loss: 1.8600 - val_accuracy: 0.4334\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.8616 - accuracy: 0.4315 - val_loss: 1.8453 - val_accuracy: 0.4438\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.8472 - accuracy: 0.4409 - val_loss: 1.8308 - val_accuracy: 0.4514\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.8330 - accuracy: 0.4493 - val_loss: 1.8164 - val_accuracy: 0.4616\n",
      "18333/18333 [==============================] - 1s 55us/sample - loss: 1.8277 - accuracy: 0.4539\n",
      "[CV] ............... n_neurons=241, learning_rate=1e-05, total= 1.9min\n",
      "[CV] n_neurons=241, learning_rate=1e-05 ..............................\n",
      "2 241 1e-05\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 2.4205 - accuracy: 0.1015 - val_loss: 2.3869 - val_accuracy: 0.1044\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.3735 - accuracy: 0.1059 - val_loss: 2.3459 - val_accuracy: 0.1104\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.3358 - accuracy: 0.1184 - val_loss: 2.3120 - val_accuracy: 0.1296\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.3041 - accuracy: 0.1412 - val_loss: 2.2829 - val_accuracy: 0.1490\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.2763 - accuracy: 0.1645 - val_loss: 2.2570 - val_accuracy: 0.1716\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.2514 - accuracy: 0.1819 - val_loss: 2.2336 - val_accuracy: 0.1890\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.2287 - accuracy: 0.1991 - val_loss: 2.2120 - val_accuracy: 0.2054\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.2077 - accuracy: 0.2150 - val_loss: 2.1918 - val_accuracy: 0.2186\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.1880 - accuracy: 0.2335 - val_loss: 2.1728 - val_accuracy: 0.2448\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.1694 - accuracy: 0.2574 - val_loss: 2.1548 - val_accuracy: 0.2680\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.1518 - accuracy: 0.2816 - val_loss: 2.1376 - val_accuracy: 0.2962\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.1349 - accuracy: 0.3052 - val_loss: 2.1211 - val_accuracy: 0.3198\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.1187 - accuracy: 0.3247 - val_loss: 2.1052 - val_accuracy: 0.3374\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.1031 - accuracy: 0.3421 - val_loss: 2.0897 - val_accuracy: 0.3572\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.0879 - accuracy: 0.3589 - val_loss: 2.0747 - val_accuracy: 0.3740\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.0732 - accuracy: 0.3740 - val_loss: 2.0601 - val_accuracy: 0.3952\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.0588 - accuracy: 0.3884 - val_loss: 2.0457 - val_accuracy: 0.4132\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 2.0447 - accuracy: 0.4034 - val_loss: 2.0316 - val_accuracy: 0.4284\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.0309 - accuracy: 0.4179 - val_loss: 2.0178 - val_accuracy: 0.4426\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 3s 90us/sample - loss: 2.0173 - accuracy: 0.4316 - val_loss: 2.0041 - val_accuracy: 0.4552\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.0039 - accuracy: 0.4448 - val_loss: 1.9906 - val_accuracy: 0.4666\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 1.9907 - accuracy: 0.4576 - val_loss: 1.9773 - val_accuracy: 0.4760\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 1.9776 - accuracy: 0.4696 - val_loss: 1.9641 - val_accuracy: 0.4878\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 93us/sample - loss: 1.9647 - accuracy: 0.4798 - val_loss: 1.9510 - val_accuracy: 0.4966\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 94us/sample - loss: 1.9519 - accuracy: 0.4907 - val_loss: 1.9381 - val_accuracy: 0.5066\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 113us/sample - loss: 1.9392 - accuracy: 0.5000 - val_loss: 1.9253 - val_accuracy: 0.5158\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 1.9267 - accuracy: 0.5091 - val_loss: 1.9125 - val_accuracy: 0.5262\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 1.9142 - accuracy: 0.5171 - val_loss: 1.8999 - val_accuracy: 0.5338\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 1.9019 - accuracy: 0.5242 - val_loss: 1.8874 - val_accuracy: 0.5386\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 1.8896 - accuracy: 0.5310 - val_loss: 1.8749 - val_accuracy: 0.5442\n",
      "18333/18333 [==============================] - 2s 105us/sample - loss: 1.8763 - accuracy: 0.5354\n",
      "[CV] ............... n_neurons=241, learning_rate=1e-05, total= 1.8min\n",
      "[CV] n_neurons=219, learning_rate=0.1 ................................\n",
      "2 219 0.1\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.5828 - accuracy: 0.7900 - val_loss: 0.4287 - val_accuracy: 0.8486\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 5s 124us/sample - loss: 0.4160 - accuracy: 0.8463 - val_loss: 0.3838 - val_accuracy: 0.8620\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.3686 - accuracy: 0.8627 - val_loss: 0.3492 - val_accuracy: 0.8742\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.3450 - accuracy: 0.8709 - val_loss: 0.3374 - val_accuracy: 0.8776\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 112us/sample - loss: 0.3213 - accuracy: 0.8811 - val_loss: 0.3493 - val_accuracy: 0.8708\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 113us/sample - loss: 0.3029 - accuracy: 0.8875 - val_loss: 0.3381 - val_accuracy: 0.8776\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.2885 - accuracy: 0.8913 - val_loss: 0.3216 - val_accuracy: 0.8802\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.2750 - accuracy: 0.8978 - val_loss: 0.3774 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.2648 - accuracy: 0.9005 - val_loss: 0.3248 - val_accuracy: 0.8816\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.2540 - accuracy: 0.9038 - val_loss: 0.3336 - val_accuracy: 0.8788\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.2438 - accuracy: 0.9086 - val_loss: 0.3121 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.2354 - accuracy: 0.9100 - val_loss: 0.3175 - val_accuracy: 0.8886\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 0.2267 - accuracy: 0.9146 - val_loss: 0.3148 - val_accuracy: 0.8840\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 111us/sample - loss: 0.2172 - accuracy: 0.9192 - val_loss: 0.3613 - val_accuracy: 0.8748\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 0.2109 - accuracy: 0.9194 - val_loss: 0.3213 - val_accuracy: 0.8894\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.2026 - accuracy: 0.9232 - val_loss: 0.3239 - val_accuracy: 0.8882\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1973 - accuracy: 0.9249 - val_loss: 0.3267 - val_accuracy: 0.8908\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 0.1891 - accuracy: 0.9282 - val_loss: 0.3259 - val_accuracy: 0.8880\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1855 - accuracy: 0.9293 - val_loss: 0.3098 - val_accuracy: 0.8952\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.1764 - accuracy: 0.9325 - val_loss: 0.3553 - val_accuracy: 0.8844\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1721 - accuracy: 0.9342 - val_loss: 0.3133 - val_accuracy: 0.9012\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.1688 - accuracy: 0.9348 - val_loss: 0.3884 - val_accuracy: 0.8754\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.1630 - accuracy: 0.9366 - val_loss: 0.3320 - val_accuracy: 0.8908\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1566 - accuracy: 0.9408 - val_loss: 0.3659 - val_accuracy: 0.8774\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 0.1517 - accuracy: 0.9432 - val_loss: 0.3491 - val_accuracy: 0.8920\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 103us/sample - loss: 0.1470 - accuracy: 0.9443 - val_loss: 0.3962 - val_accuracy: 0.8758\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 106us/sample - loss: 0.1439 - accuracy: 0.9452 - val_loss: 0.3595 - val_accuracy: 0.8864\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1389 - accuracy: 0.9477 - val_loss: 0.3647 - val_accuracy: 0.8906\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 4s 102us/sample - loss: 0.1354 - accuracy: 0.9485 - val_loss: 0.4441 - val_accuracy: 0.8772\n",
      "18334/18334 [==============================] - 1s 63us/sample - loss: 0.4408 - accuracy: 0.8733\n",
      "[CV] ................. n_neurons=219, learning_rate=0.1, total= 1.9min\n",
      "[CV] n_neurons=219, learning_rate=0.1 ................................\n",
      "2 219 0.1\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 112us/sample - loss: 0.5893 - accuracy: 0.7842 - val_loss: 0.4100 - val_accuracy: 0.8576\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.4152 - accuracy: 0.8467 - val_loss: 0.4111 - val_accuracy: 0.8516\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3724 - accuracy: 0.8608 - val_loss: 0.3540 - val_accuracy: 0.8730\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3429 - accuracy: 0.8731 - val_loss: 0.4072 - val_accuracy: 0.8500\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3197 - accuracy: 0.8783 - val_loss: 0.3472 - val_accuracy: 0.8744\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3029 - accuracy: 0.8839 - val_loss: 0.3442 - val_accuracy: 0.8724\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.2880 - accuracy: 0.8912 - val_loss: 0.3438 - val_accuracy: 0.8768\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2761 - accuracy: 0.8964 - val_loss: 0.3418 - val_accuracy: 0.8792\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.2660 - accuracy: 0.8980 - val_loss: 0.3623 - val_accuracy: 0.8676\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2539 - accuracy: 0.9032 - val_loss: 0.3142 - val_accuracy: 0.8848\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.2452 - accuracy: 0.9072 - val_loss: 0.3281 - val_accuracy: 0.8840\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2351 - accuracy: 0.9116 - val_loss: 0.3480 - val_accuracy: 0.8770\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2286 - accuracy: 0.9125 - val_loss: 0.3294 - val_accuracy: 0.8826\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.2181 - accuracy: 0.9172 - val_loss: 0.3264 - val_accuracy: 0.8832\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2129 - accuracy: 0.9194 - val_loss: 0.3085 - val_accuracy: 0.8910\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.2061 - accuracy: 0.9224 - val_loss: 0.3182 - val_accuracy: 0.8894\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.1984 - accuracy: 0.9237 - val_loss: 0.3077 - val_accuracy: 0.8916\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.1929 - accuracy: 0.9275 - val_loss: 0.3385 - val_accuracy: 0.8906\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1877 - accuracy: 0.9277 - val_loss: 0.3344 - val_accuracy: 0.8848\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.1800 - accuracy: 0.9313 - val_loss: 0.3769 - val_accuracy: 0.8764\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.1732 - accuracy: 0.9326 - val_loss: 0.3376 - val_accuracy: 0.8876\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.1698 - accuracy: 0.9347 - val_loss: 0.3356 - val_accuracy: 0.8874\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.1639 - accuracy: 0.9370 - val_loss: 0.3437 - val_accuracy: 0.8896\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.1605 - accuracy: 0.9393 - val_loss: 0.3488 - val_accuracy: 0.8896\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1539 - accuracy: 0.9411 - val_loss: 0.3515 - val_accuracy: 0.8890\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1498 - accuracy: 0.9418 - val_loss: 0.3608 - val_accuracy: 0.8856\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1450 - accuracy: 0.9447 - val_loss: 0.3314 - val_accuracy: 0.8960\n",
      "18333/18333 [==============================] - 1s 60us/sample - loss: 0.3442 - accuracy: 0.8957\n",
      "[CV] ................. n_neurons=219, learning_rate=0.1, total= 1.7min\n",
      "[CV] n_neurons=219, learning_rate=0.1 ................................\n",
      "2 219 0.1\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 111us/sample - loss: 0.5891 - accuracy: 0.7878 - val_loss: 0.4162 - val_accuracy: 0.8526\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.4155 - accuracy: 0.8483 - val_loss: 0.4095 - val_accuracy: 0.8532\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3711 - accuracy: 0.8622 - val_loss: 0.3889 - val_accuracy: 0.8644\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3416 - accuracy: 0.8719 - val_loss: 0.3372 - val_accuracy: 0.8760\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.3201 - accuracy: 0.8799 - val_loss: 0.3372 - val_accuracy: 0.8800\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.3025 - accuracy: 0.8871 - val_loss: 0.3164 - val_accuracy: 0.8846\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2882 - accuracy: 0.8923 - val_loss: 0.3407 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2742 - accuracy: 0.8966 - val_loss: 0.3276 - val_accuracy: 0.8810\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2660 - accuracy: 0.8994 - val_loss: 0.3416 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2543 - accuracy: 0.9035 - val_loss: 0.3189 - val_accuracy: 0.8814\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2426 - accuracy: 0.9093 - val_loss: 0.3070 - val_accuracy: 0.8894\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.2352 - accuracy: 0.9101 - val_loss: 0.3617 - val_accuracy: 0.8698\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2260 - accuracy: 0.9159 - val_loss: 0.3163 - val_accuracy: 0.8874\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.2161 - accuracy: 0.9171 - val_loss: 0.3164 - val_accuracy: 0.8862\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2115 - accuracy: 0.9188 - val_loss: 0.3046 - val_accuracy: 0.8924\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.2032 - accuracy: 0.9218 - val_loss: 0.3319 - val_accuracy: 0.8890\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1974 - accuracy: 0.9246 - val_loss: 0.3038 - val_accuracy: 0.8962\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1908 - accuracy: 0.9270 - val_loss: 0.3409 - val_accuracy: 0.8884\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1813 - accuracy: 0.9305 - val_loss: 0.3279 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.1791 - accuracy: 0.9315 - val_loss: 0.3095 - val_accuracy: 0.8904\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.1706 - accuracy: 0.9350 - val_loss: 0.3193 - val_accuracy: 0.8920\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.1680 - accuracy: 0.9342 - val_loss: 0.3658 - val_accuracy: 0.8762\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.1621 - accuracy: 0.9370 - val_loss: 0.3335 - val_accuracy: 0.8902\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.1584 - accuracy: 0.9398 - val_loss: 0.3206 - val_accuracy: 0.8946\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.1505 - accuracy: 0.9408 - val_loss: 0.3453 - val_accuracy: 0.8924\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.1504 - accuracy: 0.9421 - val_loss: 0.3618 - val_accuracy: 0.8776\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.1455 - accuracy: 0.9444 - val_loss: 0.3804 - val_accuracy: 0.8904\n",
      "18333/18333 [==============================] - 1s 59us/sample - loss: 0.3912 - accuracy: 0.8851\n",
      "[CV] ................. n_neurons=219, learning_rate=0.1, total= 1.7min\n",
      "[CV] n_neurons=245, learning_rate=0.0001 .............................\n",
      "2 245 0.0001\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 114us/sample - loss: 2.1841 - accuracy: 0.1739 - val_loss: 2.0829 - val_accuracy: 0.2886\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.9981 - accuracy: 0.3873 - val_loss: 1.9198 - val_accuracy: 0.4612\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.8473 - accuracy: 0.5230 - val_loss: 1.7771 - val_accuracy: 0.5752\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.7135 - accuracy: 0.6025 - val_loss: 1.6499 - val_accuracy: 0.6280\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 1.5945 - accuracy: 0.6376 - val_loss: 1.5372 - val_accuracy: 0.6466\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.4894 - accuracy: 0.6507 - val_loss: 1.4382 - val_accuracy: 0.6570\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.3981 - accuracy: 0.6592 - val_loss: 1.3531 - val_accuracy: 0.6644\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 1.3199 - accuracy: 0.6643 - val_loss: 1.2804 - val_accuracy: 0.6676\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.2529 - accuracy: 0.6686 - val_loss: 1.2179 - val_accuracy: 0.6732\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 4s 105us/sample - loss: 1.1952 - accuracy: 0.6725 - val_loss: 1.1642 - val_accuracy: 0.6754\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.1453 - accuracy: 0.6766 - val_loss: 1.1175 - val_accuracy: 0.6802\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 1.1020 - accuracy: 0.6804 - val_loss: 1.0769 - val_accuracy: 0.6840\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 1.0642 - accuracy: 0.6849 - val_loss: 1.0415 - val_accuracy: 0.6900\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 1.0310 - accuracy: 0.6898 - val_loss: 1.0104 - val_accuracy: 0.6936\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 1.0017 - accuracy: 0.6946 - val_loss: 0.9827 - val_accuracy: 0.6968\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.9757 - accuracy: 0.7000 - val_loss: 0.9577 - val_accuracy: 0.7046\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.9523 - accuracy: 0.7047 - val_loss: 0.9356 - val_accuracy: 0.7072\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.9313 - accuracy: 0.7095 - val_loss: 0.9155 - val_accuracy: 0.7124\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.9122 - accuracy: 0.7137 - val_loss: 0.8975 - val_accuracy: 0.7168\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.8948 - accuracy: 0.7180 - val_loss: 0.8807 - val_accuracy: 0.7208\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8789 - accuracy: 0.7230 - val_loss: 0.8653 - val_accuracy: 0.7264\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8642 - accuracy: 0.7252 - val_loss: 0.8512 - val_accuracy: 0.7298\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8506 - accuracy: 0.7302 - val_loss: 0.8382 - val_accuracy: 0.7332\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8379 - accuracy: 0.7329 - val_loss: 0.8262 - val_accuracy: 0.7352\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.8261 - accuracy: 0.7359 - val_loss: 0.8146 - val_accuracy: 0.7390\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.8151 - accuracy: 0.7401 - val_loss: 0.8034 - val_accuracy: 0.7420\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.8048 - accuracy: 0.7432 - val_loss: 0.7935 - val_accuracy: 0.7490\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 4s 108us/sample - loss: 0.7950 - accuracy: 0.7462 - val_loss: 0.7841 - val_accuracy: 0.7528\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 4s 110us/sample - loss: 0.7858 - accuracy: 0.7489 - val_loss: 0.7750 - val_accuracy: 0.7554\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.7771 - accuracy: 0.7517 - val_loss: 0.7663 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18334/18334 [==============================] - 1s 61us/sample - loss: 0.7844 - accuracy: 0.7437\n",
      "[CV] .............. n_neurons=245, learning_rate=0.0001, total= 2.0min\n",
      "[CV] n_neurons=245, learning_rate=0.0001 .............................\n",
      "2 245 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 2.2138 - accuracy: 0.2110 - val_loss: 2.1090 - val_accuracy: 0.3134\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 2.0262 - accuracy: 0.4132 - val_loss: 1.9442 - val_accuracy: 0.4904\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.8783 - accuracy: 0.5250 - val_loss: 1.8037 - val_accuracy: 0.5652\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.7486 - accuracy: 0.5716 - val_loss: 1.6791 - val_accuracy: 0.5948\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 1.6324 - accuracy: 0.5979 - val_loss: 1.5677 - val_accuracy: 0.6156\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.5284 - accuracy: 0.6154 - val_loss: 1.4685 - val_accuracy: 0.6290\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.4362 - accuracy: 0.6258 - val_loss: 1.3815 - val_accuracy: 0.6396\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.3553 - accuracy: 0.6342 - val_loss: 1.3055 - val_accuracy: 0.6480\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.2848 - accuracy: 0.6410 - val_loss: 1.2395 - val_accuracy: 0.6530\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.2237 - accuracy: 0.6464 - val_loss: 1.1828 - val_accuracy: 0.6572\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 1.1711 - accuracy: 0.6509 - val_loss: 1.1336 - val_accuracy: 0.6628\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.1255 - accuracy: 0.6554 - val_loss: 1.0911 - val_accuracy: 0.6682\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 1.0858 - accuracy: 0.6600 - val_loss: 1.0539 - val_accuracy: 0.6730\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.0511 - accuracy: 0.6647 - val_loss: 1.0215 - val_accuracy: 0.6760\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.0206 - accuracy: 0.6693 - val_loss: 0.9926 - val_accuracy: 0.6830\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.9935 - accuracy: 0.6742 - val_loss: 0.9672 - val_accuracy: 0.6878\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.9693 - accuracy: 0.6783 - val_loss: 0.9443 - val_accuracy: 0.6926\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.9476 - accuracy: 0.6831 - val_loss: 0.9237 - val_accuracy: 0.6978\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.9281 - accuracy: 0.6874 - val_loss: 0.9052 - val_accuracy: 0.7012\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.9104 - accuracy: 0.6918 - val_loss: 0.8886 - val_accuracy: 0.7050\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.8942 - accuracy: 0.6966 - val_loss: 0.8732 - val_accuracy: 0.7122\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.8794 - accuracy: 0.7013 - val_loss: 0.8592 - val_accuracy: 0.7150\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.8657 - accuracy: 0.7055 - val_loss: 0.8459 - val_accuracy: 0.7194\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.8531 - accuracy: 0.7102 - val_loss: 0.8339 - val_accuracy: 0.7206\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.8413 - accuracy: 0.7131 - val_loss: 0.8225 - val_accuracy: 0.7262\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.8302 - accuracy: 0.7174 - val_loss: 0.8122 - val_accuracy: 0.7272\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.8200 - accuracy: 0.7211 - val_loss: 0.8021 - val_accuracy: 0.7334\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 0.8102 - accuracy: 0.7242 - val_loss: 0.7930 - val_accuracy: 0.7384\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 106us/sample - loss: 0.8011 - accuracy: 0.7293 - val_loss: 0.7838 - val_accuracy: 0.7384\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 104us/sample - loss: 0.7924 - accuracy: 0.7309 - val_loss: 0.7755 - val_accuracy: 0.7448\n",
      "18333/18333 [==============================] - 1s 57us/sample - loss: 0.7869 - accuracy: 0.7368\n",
      "[CV] .............. n_neurons=245, learning_rate=0.0001, total= 1.9min\n",
      "[CV] n_neurons=245, learning_rate=0.0001 .............................\n",
      "2 245 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 2.2590 - accuracy: 0.1481 - val_loss: 2.1418 - val_accuracy: 0.2366\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 2.0489 - accuracy: 0.3516 - val_loss: 1.9674 - val_accuracy: 0.4318\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 1.8958 - accuracy: 0.4942 - val_loss: 1.8219 - val_accuracy: 0.5504\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.7630 - accuracy: 0.5807 - val_loss: 1.6931 - val_accuracy: 0.6092\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 1.6447 - accuracy: 0.6238 - val_loss: 1.5785 - val_accuracy: 0.6394\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.5394 - accuracy: 0.6435 - val_loss: 1.4770 - val_accuracy: 0.6566\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 1.4465 - accuracy: 0.6541 - val_loss: 1.3885 - val_accuracy: 0.6658\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.3649 - accuracy: 0.6606 - val_loss: 1.3111 - val_accuracy: 0.6704\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.2938 - accuracy: 0.6671 - val_loss: 1.2442 - val_accuracy: 0.6738\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.2320 - accuracy: 0.6724 - val_loss: 1.1865 - val_accuracy: 0.6808\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.1787 - accuracy: 0.6765 - val_loss: 1.1366 - val_accuracy: 0.6856\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.1323 - accuracy: 0.6815 - val_loss: 1.0935 - val_accuracy: 0.6882\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.0919 - accuracy: 0.6857 - val_loss: 1.0556 - val_accuracy: 0.6932\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 1.0565 - accuracy: 0.6913 - val_loss: 1.0227 - val_accuracy: 0.6964\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.0253 - accuracy: 0.6943 - val_loss: 0.9931 - val_accuracy: 0.7040\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.9975 - accuracy: 0.6987 - val_loss: 0.9672 - val_accuracy: 0.7052\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.9728 - accuracy: 0.7028 - val_loss: 0.9438 - val_accuracy: 0.7110\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.9505 - accuracy: 0.7060 - val_loss: 0.9227 - val_accuracy: 0.7174\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.9305 - accuracy: 0.7115 - val_loss: 0.9037 - val_accuracy: 0.7198\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 0.9123 - accuracy: 0.7140 - val_loss: 0.8864 - val_accuracy: 0.7264\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8957 - accuracy: 0.7180 - val_loss: 0.8707 - val_accuracy: 0.7276\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 4s 99us/sample - loss: 0.8805 - accuracy: 0.7206 - val_loss: 0.8564 - val_accuracy: 0.7312\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.8664 - accuracy: 0.7240 - val_loss: 0.8427 - val_accuracy: 0.7364\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.8534 - accuracy: 0.7272 - val_loss: 0.8303 - val_accuracy: 0.7362\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.8414 - accuracy: 0.7295 - val_loss: 0.8188 - val_accuracy: 0.7408\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.8300 - accuracy: 0.7329 - val_loss: 0.8080 - val_accuracy: 0.7434\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.8195 - accuracy: 0.7361 - val_loss: 0.7979 - val_accuracy: 0.7456\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 0.8096 - accuracy: 0.7379 - val_loss: 0.7886 - val_accuracy: 0.7486\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 4s 98us/sample - loss: 0.8003 - accuracy: 0.7410 - val_loss: 0.7794 - val_accuracy: 0.7490\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 0.7914 - accuracy: 0.7434 - val_loss: 0.7708 - val_accuracy: 0.7528\n",
      "18333/18333 [==============================] - 1s 62us/sample - loss: 0.7848 - accuracy: 0.7436\n",
      "[CV] .............. n_neurons=245, learning_rate=0.0001, total= 1.9min\n",
      "[CV] n_neurons=94, learning_rate=0.0001 ..............................\n",
      "2 94 0.0001\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 86us/sample - loss: 2.2446 - accuracy: 0.2075 - val_loss: 2.1712 - val_accuracy: 0.2844\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 2.1190 - accuracy: 0.3047 - val_loss: 2.0647 - val_accuracy: 0.3444\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 2.0207 - accuracy: 0.3733 - val_loss: 1.9719 - val_accuracy: 0.4164\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 1.9311 - accuracy: 0.4336 - val_loss: 1.8833 - val_accuracy: 0.4584\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 1.8429 - accuracy: 0.4778 - val_loss: 1.7936 - val_accuracy: 0.4980\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 1.7524 - accuracy: 0.5235 - val_loss: 1.7017 - val_accuracy: 0.5560\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.6613 - accuracy: 0.5711 - val_loss: 1.6110 - val_accuracy: 0.5986\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.5729 - accuracy: 0.6058 - val_loss: 1.5240 - val_accuracy: 0.6274\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.4886 - accuracy: 0.6288 - val_loss: 1.4417 - val_accuracy: 0.6450\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 1.4096 - accuracy: 0.6449 - val_loss: 1.3656 - val_accuracy: 0.6552\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.3370 - accuracy: 0.6585 - val_loss: 1.2964 - val_accuracy: 0.6650\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.2716 - accuracy: 0.6678 - val_loss: 1.2345 - val_accuracy: 0.6746\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 1.2133 - accuracy: 0.6763 - val_loss: 1.1800 - val_accuracy: 0.6810\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 1.1618 - accuracy: 0.6834 - val_loss: 1.1318 - val_accuracy: 0.6870\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.1164 - accuracy: 0.6901 - val_loss: 1.0893 - val_accuracy: 0.6932\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.0763 - accuracy: 0.6945 - val_loss: 1.0517 - val_accuracy: 0.6972\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 1.0409 - accuracy: 0.6990 - val_loss: 1.0186 - val_accuracy: 0.7012\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 1.0095 - accuracy: 0.7029 - val_loss: 0.9893 - val_accuracy: 0.7050\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.9815 - accuracy: 0.7069 - val_loss: 0.9634 - val_accuracy: 0.7098\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.9566 - accuracy: 0.7103 - val_loss: 0.9399 - val_accuracy: 0.7114\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 0.9342 - accuracy: 0.7143 - val_loss: 0.9189 - val_accuracy: 0.7164\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.9141 - accuracy: 0.7178 - val_loss: 0.9000 - val_accuracy: 0.7234\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.8958 - accuracy: 0.7223 - val_loss: 0.8827 - val_accuracy: 0.7258\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.8791 - accuracy: 0.7248 - val_loss: 0.8670 - val_accuracy: 0.7296\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 0.8638 - accuracy: 0.7275 - val_loss: 0.8524 - val_accuracy: 0.7326\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 0.8499 - accuracy: 0.7303 - val_loss: 0.8386 - val_accuracy: 0.7352\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 3s 81us/sample - loss: 0.8369 - accuracy: 0.7334 - val_loss: 0.8265 - val_accuracy: 0.7364\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.8250 - accuracy: 0.7360 - val_loss: 0.8150 - val_accuracy: 0.7404\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.8138 - accuracy: 0.7390 - val_loss: 0.8043 - val_accuracy: 0.7434\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 3s 79us/sample - loss: 0.8034 - accuracy: 0.7422 - val_loss: 0.7941 - val_accuracy: 0.7446\n",
      "18334/18334 [==============================] - 1s 47us/sample - loss: 0.8138 - accuracy: 0.7313\n",
      "[CV] ............... n_neurons=94, learning_rate=0.0001, total= 1.5min\n",
      "[CV] n_neurons=94, learning_rate=0.0001 ..............................\n",
      "2 94 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 91us/sample - loss: 2.3781 - accuracy: 0.1553 - val_loss: 2.2554 - val_accuracy: 0.1972\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 2.1794 - accuracy: 0.2386 - val_loss: 2.1010 - val_accuracy: 0.2806\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 2.0464 - accuracy: 0.3124 - val_loss: 1.9799 - val_accuracy: 0.3616\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.9344 - accuracy: 0.3811 - val_loss: 1.8713 - val_accuracy: 0.4216\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.8314 - accuracy: 0.4400 - val_loss: 1.7697 - val_accuracy: 0.4826\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.7346 - accuracy: 0.4933 - val_loss: 1.6744 - val_accuracy: 0.5310\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.6439 - accuracy: 0.5370 - val_loss: 1.5857 - val_accuracy: 0.5746\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.5597 - accuracy: 0.5738 - val_loss: 1.5041 - val_accuracy: 0.6070\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.4826 - accuracy: 0.6003 - val_loss: 1.4299 - val_accuracy: 0.6262\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.4125 - accuracy: 0.6180 - val_loss: 1.3629 - val_accuracy: 0.6414\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 3s 81us/sample - loss: 1.3491 - accuracy: 0.6297 - val_loss: 1.3024 - val_accuracy: 0.6520\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.2921 - accuracy: 0.6393 - val_loss: 1.2481 - val_accuracy: 0.6590\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.2410 - accuracy: 0.6467 - val_loss: 1.1995 - val_accuracy: 0.6644\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.1951 - accuracy: 0.6531 - val_loss: 1.1561 - val_accuracy: 0.6698\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.1541 - accuracy: 0.6595 - val_loss: 1.1172 - val_accuracy: 0.6744\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.1174 - accuracy: 0.6647 - val_loss: 1.0827 - val_accuracy: 0.6820\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.0848 - accuracy: 0.6699 - val_loss: 1.0517 - val_accuracy: 0.6860\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.0555 - accuracy: 0.6740 - val_loss: 1.0239 - val_accuracy: 0.6950\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.0291 - accuracy: 0.6791 - val_loss: 0.9989 - val_accuracy: 0.6962\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.0054 - accuracy: 0.6831 - val_loss: 0.9765 - val_accuracy: 0.7010\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9838 - accuracy: 0.6870 - val_loss: 0.9559 - val_accuracy: 0.7040\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9642 - accuracy: 0.6912 - val_loss: 0.9375 - val_accuracy: 0.7060\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9462 - accuracy: 0.6947 - val_loss: 0.9203 - val_accuracy: 0.7108\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 0.9298 - accuracy: 0.6993 - val_loss: 0.9046 - val_accuracy: 0.7148\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 0.9147 - accuracy: 0.7020 - val_loss: 0.8901 - val_accuracy: 0.7206\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9006 - accuracy: 0.7061 - val_loss: 0.8768 - val_accuracy: 0.7212\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.8877 - accuracy: 0.7096 - val_loss: 0.8643 - val_accuracy: 0.7266\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.8756 - accuracy: 0.7125 - val_loss: 0.8528 - val_accuracy: 0.7286\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.8642 - accuracy: 0.7157 - val_loss: 0.8417 - val_accuracy: 0.7312\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.8536 - accuracy: 0.7185 - val_loss: 0.8316 - val_accuracy: 0.7364\n",
      "18333/18333 [==============================] - 1s 46us/sample - loss: 0.8464 - accuracy: 0.7261\n",
      "[CV] ............... n_neurons=94, learning_rate=0.0001, total= 1.5min\n",
      "[CV] n_neurons=94, learning_rate=0.0001 ..............................\n",
      "2 94 0.0001\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 86us/sample - loss: 2.2383 - accuracy: 0.2026 - val_loss: 2.1552 - val_accuracy: 0.2872\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 81us/sample - loss: 2.0998 - accuracy: 0.3308 - val_loss: 2.0439 - val_accuracy: 0.3786\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.9997 - accuracy: 0.4077 - val_loss: 1.9461 - val_accuracy: 0.4366\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.9046 - accuracy: 0.4614 - val_loss: 1.8484 - val_accuracy: 0.4892\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 1.8082 - accuracy: 0.5075 - val_loss: 1.7496 - val_accuracy: 0.5382\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.7119 - accuracy: 0.5444 - val_loss: 1.6525 - val_accuracy: 0.5726\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.6190 - accuracy: 0.5736 - val_loss: 1.5612 - val_accuracy: 0.5994\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.5321 - accuracy: 0.5973 - val_loss: 1.4766 - val_accuracy: 0.6250\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.4520 - accuracy: 0.6140 - val_loss: 1.3994 - val_accuracy: 0.6372\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.3794 - accuracy: 0.6277 - val_loss: 1.3299 - val_accuracy: 0.6464\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.3144 - accuracy: 0.6388 - val_loss: 1.2678 - val_accuracy: 0.6528\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.2566 - accuracy: 0.6463 - val_loss: 1.2131 - val_accuracy: 0.6606\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.2054 - accuracy: 0.6531 - val_loss: 1.1646 - val_accuracy: 0.6644\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 1.1602 - accuracy: 0.6591 - val_loss: 1.1222 - val_accuracy: 0.6708\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.1201 - accuracy: 0.6642 - val_loss: 1.0843 - val_accuracy: 0.6748\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.0845 - accuracy: 0.6693 - val_loss: 1.0510 - val_accuracy: 0.6796\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.0529 - accuracy: 0.6743 - val_loss: 1.0211 - val_accuracy: 0.6836\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 1.0246 - accuracy: 0.6783 - val_loss: 0.9944 - val_accuracy: 0.6878\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.9992 - accuracy: 0.6838 - val_loss: 0.9705 - val_accuracy: 0.6942\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9763 - accuracy: 0.6878 - val_loss: 0.9488 - val_accuracy: 0.6976\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.9556 - accuracy: 0.6932 - val_loss: 0.9290 - val_accuracy: 0.7040\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.9366 - accuracy: 0.6971 - val_loss: 0.9113 - val_accuracy: 0.7092\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 0.9192 - accuracy: 0.7023 - val_loss: 0.8945 - val_accuracy: 0.7112\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.9033 - accuracy: 0.7064 - val_loss: 0.8794 - val_accuracy: 0.7162\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 3s 80us/sample - loss: 0.8885 - accuracy: 0.7105 - val_loss: 0.8654 - val_accuracy: 0.7214\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.8748 - accuracy: 0.7149 - val_loss: 0.8523 - val_accuracy: 0.7270\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.8621 - accuracy: 0.7180 - val_loss: 0.8402 - val_accuracy: 0.7294\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 0.8501 - accuracy: 0.7215 - val_loss: 0.8290 - val_accuracy: 0.7318\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.8389 - accuracy: 0.7261 - val_loss: 0.8180 - val_accuracy: 0.7338\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 3s 79us/sample - loss: 0.8282 - accuracy: 0.7286 - val_loss: 0.8078 - val_accuracy: 0.7386\n",
      "18333/18333 [==============================] - 1s 50us/sample - loss: 0.8151 - accuracy: 0.7332\n",
      "[CV] ............... n_neurons=94, learning_rate=0.0001, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 55.1min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x14b5cf320>, as the constructor either does not set or modifies parameter n_neurons",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-59b00fe2816a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=30,\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m~/ML2/ML2/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML2/ML2/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x14b5cf320>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#param_distribs = {\n",
    "#    #\"n_hidden\": [1, 2], #[0, 1, 2, 3],\n",
    "#    #\"n_neurons\": np.arange(1, 100),\n",
    "#    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "#}\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": np.arange(50, 300),\n",
    "    \"learning_rate\": [.1, .01, .001, .0001 , .00001],\n",
    "}\n",
    "\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=30,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scipy.stats._distn_infrastructure.rv_frozen object at 0x148eac8d0>\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 2, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we are satisfied with the model's validation accuracy. The next step is to evaluate the model on the test data to see whether it generalizes well to data it has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the labels of the first three elements from the test set. For each test item you will see ten probabilities, i.e. the probability that a given item belongs to each of the respective output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly output the label of the winning class per test element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also output the respective names of the winning classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, but not least, we can plot the pictures for which we wanted to predict the labels and compare human and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
