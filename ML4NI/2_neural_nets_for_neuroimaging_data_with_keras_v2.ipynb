{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4NJVetfhJWN"
      },
      "source": [
        "**Notebook 2 – Artificial Neural Networks for neuroimaging with Keras**\n",
        "\n",
        "_This notebook tries to learn and predict labels from fMRI data._\n",
        "jens.schwarzbach@ukr.de"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8N9X2EhJWP"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/jvschw/ml4ni/blob/master/ML4NI/2_neural_nets_for_neuroimaging_data_with_keras_v2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9zYMqDFhJWP"
      },
      "source": [
        "run this cell only in google colab (uncomment before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rh33mbuhJWQ"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/jvschw/ml4ni.git\n",
        "! python3 -m pip install -U nilearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfHJ2XJuhJWQ"
      },
      "source": [
        "# Artificial Neural Networks in Neuroimaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4QZxqPNhJWR"
      },
      "source": [
        "## Forward and Reverse Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fl4_vm9hJWR"
      },
      "source": [
        "Can we read somebody’s thoughts with fMRI and machine learning?\n",
        "\n",
        "Typically, we use fMRI for producing *Statistical Parameter Maps* that indicate which voxels show activity that can be better explained by a model than by chance. We use massive univariate (i.e. voxel wise) statistics to map an explanatory variable (the experimental design) to observed data (voxel time-courses). This process is called **forward inference**. In decoding or **reverse inference** we try to find the mapping from observed data (patterns of activity or some SPMs) to an explanatory variable (scores or labels). Reverse inference is exactly what we want to achieve in fMRI-based mind reading: We want to find out what went on in the participant’s mind (labels) based on patterns of brain activity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpPMLchYhJWR"
      },
      "source": [
        "<img src=\"https://github.com/jvschw/ml4ni/blob/master/ML4NI/images/ni/forward_and_reverse_inference.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk1iy1yGhJWS"
      },
      "source": [
        "**Figure 1.** *In encoding or forward inference we use massive univariate (i.e. voxel wise) statistics to map an explanatory variable (the experimental design) to observed data (voxel time-courses). This addresses the question of which voxels show activity that can be better explained by a particular model than by chance. In decoding or reverse inference we try to find the mapping from observed data (patterns of activity) to an explanatory variable (scores or labels).* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r0KKIXJhJWS"
      },
      "source": [
        "## Task and data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gAm_JcyhJWS"
      },
      "source": [
        "Here, we will start with brain- or mind reading by creating a model to predict from brain activity what the participant was *doing*. Then we will use that model to predict what the participant was *thinking of doing*. \n",
        "\n",
        "We conducted an fMRI experiment with 10 runs of a foot-finger-tongue mapper and one run of motor imagery. In runs 1-10 we asked participants to move particular body parts (left index finger, right index finger, left toe, right toe, tongue in left cheek, tongue in right cheek). In run 11 we asked participants to imagine performing the respective actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PVXkK9PhJWT"
      },
      "source": [
        "<img src=\"https://github.com/jvschw/ml4ni/blob/master/ML4NI/images/ni/fft_design.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTEBBKkbhJWT"
      },
      "source": [
        "**Figure 2.** *Schematic of an experimental run. Each bar depicts a time-period of 16s, with the color indicating the task (red: wiggle the left toe, yellow: wiggle the right tow, green: move the left index finger up and down, cyan: move the right index finger up and down, blue: move the tong inside the left cheek, purple: move the tongue inside the right cheek, black: pause).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMz5sxYnhJWT"
      },
      "source": [
        "**Part** I of our exercise is to perform the forward inference:  Starting from the participant’s action or imagination (e.g. moving the left index finger) we want to find out which brain areas activate. In **part II**, which is about reverse inference, we want to build and train a classifier that can predict the experimental conditions in data like this. Finally, in **part III** on cross-decoding we will test whether a model that has been trained on action execution can predict the labels of the eleventh run when the participant only imagined the movements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCdgffirhJWU"
      },
      "source": [
        "# Part I: Forward inference (estimate a model of brain activity resulting from experimental manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6CIypF-hJWU"
      },
      "source": [
        "How to perform forward inference is handled in several fMRI classes. You can find excellent tutorials at https://fsl.fmrib.ox.ac.uk/fslcourse/.\n",
        "In a nutshell: With fMRI we measure the blood oxygenation level dependent (BOLD) response of the brain, which we take as a measure of brain activity. The 4D-images that we obtain can be regarded as many timeseries that are arranged in 3D. The figure below shows us the timeseries (in red) of one voxel (volumetric pixel). In fMRI data analysis we test to which level a set of processes (predictors), which should produce timeseries that are timelocked to occurences of these processes (multiple humps in the two blue lines), can explain the data better than a null-hypothesis (that these processes do not matter in a given voxel). \n",
        "\n",
        "We can formulate this problem as a regression problem in the context of the General Linear Model (GLM):\n",
        "\\begin{align}\n",
        "y = \\beta X + e\n",
        "\\end{align}\n",
        "with y being the to-be-explained timecourse (your observation), X being the design matrix (your hypothesis: which process -encoded in the columns- happened when -encoded in the rows-), \\$\\beta\\$ being a vector with one weight per predictor (this is what you want to find out: how high should each \\$\\beta\\$ be such that the particular model explains the data best?), and e being the error that your model cannot explain.\n",
        "\n",
        "In massive univariate testing we calculate one set of beta values for each voxel, and we create as many beta maps as we have predictors. If you devide beta by the standard deviation of the error (one per voxel), you get a t-map. This is what we will be working with: a set of t-maps (one for each experimental condition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "252blhfahJWU"
      },
      "source": [
        "<img src=\"https://github.com/jvschw/ml4ni/blob/master/ML4NI/images/ni/mass_univariate_GLM_small.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPlyBZ9ghJWV"
      },
      "source": [
        "**Figure 3.** Simplified workflow of a univariate GLM-based fMRI analysis. Observed timecourse y (red), design matrix X with predictors x1 and x2 (blue) and error (black). This particular GLM aims at explaining y with βX, i.e. $β_{1}$$x_{1}$ + $β_{2}$$x_{2}$  by finding those β-weights that minimize the squared error (of y-βX).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7uiONTZhJWV"
      },
      "source": [
        "Let's explore some data. We have a low-resolution structural (T1-weighted) scan and we have a statistical parameter map from the first run that contains the t-values for the statistical contrast of moving the left index finger vs baseline (FING_L).\n",
        "Using the nibabel (https://nipy.org/nibabel/) library we can read data in a host of imaging formats, here compressed nifti. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eqg0jwshJWV"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib #if this throws an error consider 'python3 -m pip install -U nibabel'\n",
        "\n",
        "#Load structural scan\n",
        "example_anat = '/content/ml4ni/ML4NI/parameterMaps/FFT001_T1_lores.nii.gz'\n",
        "#example_anat = './parameterMaps/FFT001_T1_lores.nii.gz'\n",
        "\n",
        "imgT1 = nib.load(example_anat)\n",
        "\n",
        "#load statistical parameter map for one run\n",
        "example_func = '/content/ml4ni/ML4NI/parameterMaps/FFT001_R01_TSTAT1.nii.gz'\n",
        "#example_func = './parameterMaps/FFT001_R01_TSTAT1.nii.gz'\n",
        "imgSPM = nib.load(example_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aHu3L7WhJWW"
      },
      "source": [
        "With nilearn (https://nilearn.github.io), a library for machine learning projects targeted at neuroimaging, we can visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4xckv-NhJWW"
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\n",
        "from nilearn.image import mean_img\n",
        "plotting.view_img(imgSPM, bg_img=imgT1, threshold=2.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQZQN-8hJWW"
      },
      "source": [
        "**Figure 4.** Rendering of statistical parameter map of one subject and one run in which the participant moved the left index finger. The background is a low-resolution rendering of that participant's structural scan. [click and move the mouse] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgn4dpSFhJWX"
      },
      "source": [
        "From our mapping experiment described above we have created one nifti-file (FFT001.nii.gz) that contains 66 t-maps, which are the t-maps of all 11 runs with each run producing 6 maps, one per condition (\"FingL\", \"FingR\", \"FootL\", \"FootR\", \"TongueL\", \"TongueR\"). In the next parts we will use these t-maps as features for machine learning and the ordered list of experimental conditions as labels. Let's load the whole stack of 3D maps and extract all features into a big 4D matrix (space x number_of_maps)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0t3WTNZhJWX"
      },
      "outputs": [],
      "source": [
        "#fNameMaps = './parameterMaps/FFT001.nii.gz'\n",
        "fNameMaps = '/content/ml4ni/ML4NI/parameterMaps/FFT001.nii.gz'\n",
        "imgSPM = nib.load(fNameMaps)\n",
        "\n",
        "#extract features (t-values)\n",
        "X4D = imgSPM.get_fdata()\n",
        "print(\"Data dimensionality (xDim, yDim, zDim, noOfMaps) is:\", X4D.shape) #(xDim, yDim, zDim, noOfMaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62VWArv-hJWX"
      },
      "source": [
        "Each of our 66 SPMs (11 runs with 6 stimulation-blocks per run) is 3D [64, 100, 67] (voxels in the x-direction right to left, voxels in the y-direction front to back, and voxels in the z-direction top to bottom). For machine learning we want to flatten them into vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-Gd7v39hJWX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "xDim=X4D.shape[0];\n",
        "yDim=X4D.shape[1];\n",
        "zDim=X4D.shape[2];\n",
        "numberOfMaps=X4D.shape[3];\n",
        "Xflat = np.empty([numberOfMaps, xDim*yDim*zDim])\n",
        "counter = 0\n",
        "for iMap in range(numberOfMaps):\n",
        "    thisMap = X4D[:, :, :,iMap]\n",
        "    Xflat[iMap,:] = thisMap.flatten()\n",
        "print('Dimensionality of feature map Xflat', Xflat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZQ_4WuchJWY"
      },
      "source": [
        "Now we are ready to visualize all the features that we are going to use for predicting the labels or targets (brain states). Do you think that all features are informative?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J1cBIkGhJWY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(32, 8))\n",
        "ax = fig.add_subplot(111)\n",
        "hImage = ax.imshow(Xflat, cmap=mpl.cm.hsv)\n",
        "ax.set_aspect(aspect=2000)\n",
        "ax.set_xlabel('features');\n",
        "ax.set_ylabel('maps');\n",
        "fig.colorbar(hImage);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyvTnrQbhJWY"
      },
      "source": [
        "**Figure 5.** 2D-heatmap of t-values for the entire experiment. Rows 0-5 refer to \"FingL\", \"FingR\", \"FootL\", \"FootR\", \"TongueL\", \"TongueR\", repectively for run 1. This arrangement is repeated for all runs, yielding 66 maps with 428800 features each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1cuKlJ6hJWY"
      },
      "source": [
        "And here is how we create our targets (I actually prefer calling targets 'labels'). We will use the experimental conditions as targets. The stacked maps are organized in 11 (number of runs) x 6 (number of conditions) in a fixed sequence. We will code conditions as targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOpRXI-GhJWZ"
      },
      "outputs": [],
      "source": [
        "targets = np.empty([66, 1], dtype=int) #condition number\n",
        "\n",
        "counter=0\n",
        "for iRun in range(11):\n",
        "    for iCond in range(6):\n",
        "        targets[counter] = iCond #0-5\n",
        "        counter+=1\n",
        "class_names = [\"FingL\", \"FingR\", \"FootL\", \"FootR\", \"TongueL\", \"TongueR\"]\n",
        "print(\"targets: \", targets.transpose()) #to save screen real estate, transpose for printing\n",
        "print('target-dimensions: ', targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm76s1ZYhJWZ"
      },
      "source": [
        "# Part II: Reverse inference (predict label, i.e. mental state, from patterns of brain activity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWaNZyOghJWZ"
      },
      "source": [
        "Now we have everything we need for reverse inference, i.e. for predicting the label (or mental state) from features (patterns of brain activity)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2By_x1v3hJWZ"
      },
      "source": [
        "## The general strategy of training a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMPtaZ19hJWa"
      },
      "source": [
        "Our goal is to train a model on existing data that will generalize well on new data. But how can you tell whether your model will generalize well on new data? You cannot know, because new data will a) come in the future and b) you will not know exactly what the new data will be (if you knew, there wouldn't be much predicting to do, right?). In the meantime you can try to *estimate* how well the model will generalize. \n",
        "When we evaluate an algorithm, we are in fact evaluating all steps in the procedure, including how the training data was prepared (e.g. scaling), the choice of algorithm (e.g. deep learning), and how the chosen algorithm was configured (e.g. number_of_hidden_layers=3).\n",
        "The performance measure calculated on the predictions is an estimate of the skill of the whole procedure.\n",
        "We generalize the performance measure from:\n",
        "“the skill of the procedure on the test set“\n",
        "to\n",
        "“the skill of the procedure on unseen data“.\n",
        "To this aim you take your existing data and split it. Here are two splitting strategies that depend on whether you have a lot of labeled data or not.  \n",
        "\n",
        "*If you have a lot of data*, your first split is into Training Data and Test Data (see also Figure 6 below). Then you use further splits on your training data for k-fold cross validation in order to finetune so-called hyperparameters (number of hidden layers, number of neurons per layer, learning rate, activation functions and so forth). Try to find the best combination of hyperparameters by training on part of the data (white) and estimate on unseen data (yellow). You will get k accuracies, one for each split. The average and standard deviation of these k accuracies will be your estimator for how well the model generalizes (the average) and how confident you are with your estimate (the spread).\n",
        "\n",
        "Since this estimate is biased due to the fact that you have used all of your data during cross validation, you can now generate an unbiased estimate of your accuracy (but not of the spread) by retraining your model on all the training data and predicting the (known) labels of the test dataset. If the prediction accuracy on the test dataset is similar to the estimated accuracy, you have good reasons to assume that a) your estimate was good, and b) that your model did not overfit the training data. If your prediction accuracy on the test data is much lower than its estimate, it is quite likely that your model did overfit the training data or that you made a mistake. However, do not tune your model based on knowledge about the test data.  \n",
        "\n",
        "*If you do **not** have a lot of data*, you may not be able to afford the first split into training and test data. You will use all of your data for training. Like in the procedure above, you can use cross validation to estimate how well your model will generalize to unseen data. However, you have no chance of checking this, because you do not have any test data. But if your resampling procedure was done properly, this value will only be slightly biased. Now it is time to retrain your final model on all the data you have available. This procedure leads to biased (inflated) expectations about generalizability but it  may be better than training your model on an even smaller dataset and actually performing worse.\n",
        "***Since we do not have a lot of data in this example, we take this latter approach here.***\n",
        "<img src=\"https://github.com/jvschw/ml4ni/blob/master/ML4NI/images/ni/crossvalidation_jvs_small.png?raw=1\">\n",
        "\n",
        "**Figure 6.** Data-splitting for training and evaluating a model. **Training Dataset:** The sample of data used to fit the model. **Validation Dataset:** The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
        "**Test Dataset:** The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset. **Notes:** The validation dataset may also play a role in other forms of model preparation, such as feature selection. The final model could be fit on the aggregate of the training and validation datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYNmWDCVhJWb"
      },
      "source": [
        "Find below a small example on crossvalidation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnrrAwtahJWb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "X = np.array([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"])\n",
        "kf = KFold(n_splits=10) #try with 5\n",
        "for train, test in kf.split(X):\n",
        "    print(\"%s %s\" % (train, test))\n",
        "\n",
        "for train, test in kf.split(X):\n",
        "    print(\"%s %s\" % (X[train], X[test]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FszTSHFPhJWc"
      },
      "source": [
        "## The general strategy of crossvalidation in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKQ_s6y5hJWd"
      },
      "source": [
        "Below there is an outline of how to implement a crossvalidation approach with Keras (adapted from https://datascience.stackexchange.com/questions/11747/cross-validation-in-keras). This code is meant as a preview of the steps that follow when we fill these different functions with code.\n",
        "\n",
        "**NOTE**: executing the cell below should produce errors because this is incomplete code only meant to provide an overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1zIbKH_hJWd"
      },
      "outputs": [],
      "source": [
        "#!!!DO NOT EXECUTE!!! \n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def load_data():\n",
        "    # load your data using this function\n",
        "\n",
        "def create model():\n",
        "    # create your model using this function\n",
        "\n",
        "def train_and_evaluate__model(model, data_train, labels_train, data_test, labels_test):\n",
        "    # fit and evaluate here.\n",
        "    #model.fit...\n",
        "\n",
        "\n",
        "#MAIN PROGRAM\n",
        "#set number of desired folds\n",
        "n_folds = 10\n",
        "\n",
        "#load data\n",
        "data, labels, header_info = load_data()\n",
        "\n",
        "#create shuffled, representative folds\n",
        "skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
        "\n",
        "#loop over folds\n",
        "#     create model\n",
        "#     train and evaluate model\n",
        "for i, (train, test) in enumerate(skf):\n",
        "    print \"Running Fold\", i+1, \"/\", n_folds\n",
        "    model = None # Clearing the NN.\n",
        "    model = create_model()\n",
        "    train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsHid7VUhJWd"
      },
      "source": [
        "## Implementation of crossvalidation for fMRI execution-mapper in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_py_bILhJWd"
      },
      "source": [
        "### Prerequisites\n",
        "This section imports the necessary libraries and defines dome utility functions for plotting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAr5_ZSKhJWe"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=18)\n",
        "mpl.rc('xtick', labelsize=16)\n",
        "mpl.rc('ytick', labelsize=16)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ni\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnESHFyehJWe"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2pHGuWWhJWe"
      },
      "source": [
        "We will use two datasets: 1.) a structural scan which we use for feature selection (use brain-voxels only), and 2) a statistical parameter maps (SPMs) from 10 runs with 6 conditions each of a Foot-Finger-Tongue movement mapper. Each run's maps are ordered alphabetically (\"FingL\", \"FingR\", \"FootL\", \"FootR\", \"TongueL\", \"TongueR\").\n",
        "\n",
        "The SPMs are stacked 3D-maps ([x, y, z, numberOfMaps]). We flatten them to one vector per map (with as many elements as there are voxels [1, x `*`y`*`z]). Then we mask them, i.e. we only select elements that are located in the brain ([1, numberOfBrainVoxels]). Finally, we stack these vectors such that we obtain a matrix (nMaps=60,nFeatures=numberOfBrainVoxels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YAP4yr8hJWf"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib #if this throws an error consider 'python3 -m pip install -U nibabel'\n",
        "\n",
        "def load_data():\n",
        "    #load a structural scan and use brain voxels as mask for statistical parameter maps (SPMs)\n",
        "    \n",
        "    #Load structural scan\n",
        "    ref_anat = '/content/ml4ni/ML4NI/parameterMaps/FFT001_T1_lores.nii.gz'\n",
        "    #ref_anat = './parameterMaps/FFT001_T1_lores.nii.gz'\n",
        "    imgT1 = nib.load(ref_anat)\n",
        "    \n",
        "    #extract features (voxel intensities of the structural scan)\n",
        "    XT1 = imgT1.get_fdata() \n",
        "    \n",
        "    #create mask from structural scan where voxels have a value higher than 0\n",
        "    msk2 = XT1>0 \n",
        "    nMaskedVoxels = msk2.sum()\n",
        "    \n",
        "    #Load SPMs (stacked 3D maps)\n",
        "    fNameSPM = '/content/ml4ni/ML4NI/parameterMaps/FFT001.nii.gz'\n",
        "    #fNameSPM = './parameterMaps/FFT001.nii.gz'\n",
        "    imgSPM = nib.load(fNameSPM)\n",
        "    \n",
        "    #extract features (t-values)\n",
        "    XSPM = imgSPM.get_fdata() \n",
        "    print(\"Data dimensionality is:\", XSPM.shape)\n",
        "    nMaps=XSPM.shape[3]\n",
        "    \n",
        "    #create flattened and masked feature matrix[nMaps,nFeaturesInsideBrain]\n",
        "    XflatMasked = np.empty([nMaps, nMaskedVoxels])\n",
        "    for iMap in range(nMaps):\n",
        "        #extract one flattened map\n",
        "        tmpFlat = XSPM[:, :, :,iMap].flatten()\n",
        "        #mask flattened map and assign to feature matrix\n",
        "        XflatMasked[iMap,:]=tmpFlat[XT1.flatten()>0] \n",
        "    print(\"Dimensionality of flattened and masked feature matrix: \", XflatMasked.shape)    \n",
        "    \n",
        "    #SPLIT EXECUTION DATA (MAPS 1:60) FROM IMAGERY DATA (MAPS 61-66)\n",
        "    #first 60 maps 10 runs with 6 conditions each\n",
        "    dataLearn=XflatMasked[:60] \n",
        "    #last 6 maps (run 11 with 6 conditions). This is not really a holdout map, since this\n",
        "    #is imagery data, whereas the first 60 maps are execution data\n",
        "    dataHoldout=XflatMasked[60:] \n",
        "    \n",
        "    #CREATE LABELS\n",
        "    #labels\n",
        "    #chunks = np.empty([66, 1], dtype=int) #run number [not yet used]\n",
        "    labels = np.empty([nMaps, 1], dtype=int) #condition number\n",
        "    counter=0\n",
        "    for iRun in range(11):\n",
        "        for iCond in range(6):\n",
        "            #chunks[counter] = iRun #11 runs (0-10)\n",
        "            labels[counter] = iCond #6 conditions (0-5)\n",
        "            counter+=1\n",
        "    labelsLearn=labels[:60] #first 60 (0:59) execution\n",
        "    labelsHoldout=labels[60:] #last 6 (60:65) imagery\n",
        "    \n",
        "    class_names=[\"FingL\", \"FingR\", \"FootL\", \"FootR\", \"TongueL\", \"TongueR\"]  \n",
        "    \n",
        "    return dataLearn, labelsLearn, dataHoldout, labelsHoldout, class_names, msk2;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjwGaCskhJWg"
      },
      "source": [
        "### Creating a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzvYB4MhJWg"
      },
      "source": [
        "Next comes a function that can create keras models with a variable number of hidden layers, number of neurons per layer, learning rate, and number of input features for us. This function takes up to 4 input parameters, for which we also define default values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e26jgYe_hJWg"
      },
      "outputs": [],
      "source": [
        "def create_model(n_hidden=2, n_neurons=30, learning_rate=3e-3, nFeatures=100):\n",
        "    # create your model using this function\n",
        "    print(n_hidden, n_neurons, learning_rate)\n",
        "    model = keras.models.Sequential()   \n",
        "    model.add(keras.layers.Flatten(input_shape=(nFeatures,)))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
        "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2NhDPhWhJWg"
      },
      "source": [
        "### Test and evaluate a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Bt36ychJWg"
      },
      "source": [
        "Here, we create a function that tests and evaluates a model. This function also saves the fitted model for each fold, which will come in handy for later exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56THlDQVhJWg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test, fold):\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")+\"fft_keras_model\"+'{:04d}'.format(fold)\n",
        "    run_logdir=os.path.join('./my_logs', run_id)\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    #callback functions, which will be executed during training\n",
        "    #----------------------------------------------------------\n",
        "    #send data to tensorboard, for online monitoring the training process \n",
        "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir,histogram_freq=1)\n",
        "    #checkpoint callbacks save the model in a particular state, here the best model (lowest validation-loss)\n",
        "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\"fft_keras_model\"+'{:04d}'.format(fold)+\".h5\", save_best_only=True)\n",
        "    #early stopping is a method to avoid overfitting (here defined as 10 epochs without reducing validation-loss)\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "    #----------------------------------------------------------\n",
        "    #model fitting\n",
        "    #----------------------------------------------------------\n",
        "    history = model.fit(data_train, labels_train, epochs=20, batch_size=6,\n",
        "                    validation_data=(data_test, labels_test),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
        "    \n",
        "    #----------------------------------------------------------\n",
        "    #model evaluation (performance measures and graphs)\n",
        "    #----------------------------------------------------------\n",
        "    print('Model evaluation ')\n",
        "    modEval=model.evaluate(data_test,labels_test) \n",
        "    import pandas as pd\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(False)\n",
        "    plt.gca().set_ylim(0, 1)\n",
        "    #save_fig(\"keras_learning_curves_plot\")\n",
        "    plt.show()\n",
        "    \n",
        "    return modEval, history;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqs7banIhJWh"
      },
      "source": [
        "### Main program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUWs7stUhJWh"
      },
      "source": [
        "Learn to predict different executed movements using 10-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "7lITaKIkhJWh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "#----------------------------------------------------------\n",
        "#number of folds (should be number of runs)\n",
        "#----------------------------------------------------------\n",
        "n_folds=10\n",
        "\n",
        "#----------------------------------------------------------\n",
        "#load data\n",
        "#----------------------------------------------------------\n",
        "dataLearn, labelsLearn, dataHoldout, labelsHoldout, class_names, msk2 = load_data()\n",
        "nFeatures=dataLearn.shape[1]\n",
        "\n",
        "#----------------------------------------------------------\n",
        "#TURN ON TENSORBOARD\n",
        "#----------------------------------------------------------\n",
        "#PROBABLY BETTER TO COMMENT THIS OUT WHEN RUNNING N COLAB\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir=./my_logs --port=7007  #--port=6006\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./my_logs/ \n",
        "\n",
        "#----------------------------------------------------------\n",
        "#Train and evaluate model with k-fold cross validation\n",
        "#----------------------------------------------------------\n",
        "skf = KFold(n_folds).split(dataLearn)\n",
        "history=[]\n",
        "modEval=[]\n",
        "for i, (train, test) in enumerate(skf):\n",
        "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
        "    model = None # Clearing the NN.\n",
        "    model = create_model(3, 100, 3e-3, nFeatures)\n",
        "    e,h=train_and_evaluate_model(model, dataLearn[train], labelsLearn[train],\n",
        "                                 dataLearn[test],labelsLearn[test], i)\n",
        "    modEval.append(e)\n",
        "    history.append(h)\n",
        "    print(train)\n",
        "\n",
        "#----------------------------------------------------------\n",
        "#we can estimate how well our model should perform on new data\n",
        "#by taking the mean and standard deviation or actually standard error\n",
        "#for loss and accuracy from our 10 folds\n",
        "#----------------------------------------------------------\n",
        "avgValMean = np.mean(modEval, axis=0)\n",
        "avgValStd = np.std(modEval, axis=0)\n",
        "print('Average Validation Loss    ', '{:5.3f}'.format(avgValMean[0]), ', se=', '{:5.3f}'.format(avgValStd[0]/np.sqrt(n_folds)))\n",
        "print('Average Validation Accuracy', '{:5.3f}'.format(avgValMean[1]), ', se=', '{:5.3f}'.format(avgValStd[1]/np.sqrt(n_folds)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfUr3jH8hJWh"
      },
      "source": [
        "Now we know to which degree our model should be able to generalize to new, unseen data of the same kind. If we wanted to sell this model as a brain reader for executed actions, we could advertise it with the following performance parameters.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKICZ7KuhJWh"
      },
      "outputs": [],
      "source": [
        "print('Show me your brain and I tell you what you are doing!')\n",
        "print('Estimated Loss    ', '{:5.3f}'.format(avgValMean[0]), ', se=', '{:5.3f}'.format(avgValStd[0]/np.sqrt(n_folds)))\n",
        "print('Estimated Accuracy', '{:5.3f}'.format(avgValMean[1]), ', se=', '{:5.3f}'.format(avgValStd[1]/np.sqrt(n_folds)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J0F7L0OhJWh"
      },
      "source": [
        "Over ninety percent accuracy to be expected. Not bad! But is that good? This may depend on the application. But remember, we can make such accurate predictions on the single subject level!\n",
        "By the way, we have not yet created our final model. All of the above was to estimate how good the final model will be. Creating the final model is as simple as training it on our available data from 10 runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx-jMSIyhJWh"
      },
      "outputs": [],
      "source": [
        "#create model\n",
        "model = create_model(3, 100, 3e-3, nFeatures)\n",
        "\n",
        "#fit model with early stopping (which I don't think will become effective)\n",
        "#early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss', patience=5,\n",
        "#                                                  restore_best_weights=True)\n",
        "\n",
        "finalHistory = model.fit(dataLearn, labelsLearn, epochs=20, batch_size=6)\n",
        "\n",
        "#save model\n",
        "model.save(\"FFT_execution_final.h5\")\n",
        "\n",
        "#show how the model converges\n",
        "import pandas as pd\n",
        "pd.DataFrame(finalHistory.history).plot(figsize=(8, 5))\n",
        "plt.grid(False)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lqB0nM6hJWi"
      },
      "source": [
        "# Part III. When we train on executing movements, can we predict which movement the participant imagines?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8JA1fnKhJWi"
      },
      "source": [
        "Such an approach is called cross-decoding. It is easier than you might think. When loading the data, we created a holdout dataset from the last 6 statistical parameter maps. Let's just evaluate our model on these data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAUYPoJ-hJWi"
      },
      "outputs": [],
      "source": [
        "model.evaluate(dataHoldout, labelsHoldout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWJqqBXFhJWi"
      },
      "source": [
        "Well, 33-50%. However, remember that this is 2-3 times the probability to guess this right, which is 1/6 (or 16.66%). So which imagined movements don't we really get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dtEJqURhJWi"
      },
      "outputs": [],
      "source": [
        "def annotated_confusion_matrix(cm, class_names):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm)\n",
        "\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(len(class_names)))\n",
        "    ax.set_yticks(np.arange(len(class_names)))\n",
        "    # ... and label them with the respective list entries\n",
        "    ax.set_xticklabels(class_names)\n",
        "    ax.set_yticklabels(class_names)\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\");\n",
        "    ax.set_ylabel('predicted')\n",
        "    ax.set_xlabel('exp. condition')\n",
        "\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umFt8g-ohJWi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_predHoldout = model.predict_classes(dataHoldout)\n",
        "print(\"labels: \", labelsHoldout)\n",
        "print(\"predictions: \", y_predHoldout)\n",
        "\n",
        "cm = confusion_matrix(labelsHoldout, y_predHoldout)\n",
        "annotated_confusion_matrix(cm, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NI57JbqhJWi"
      },
      "source": [
        "How to read this? Columns are the truth (experimental conditions), rows are the predictions. \n",
        "\n",
        "Are there particular tasks our model is bad at predicting?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVmEVQLyhJWi"
      },
      "source": [
        "# Sources and Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgpCvECshJWi"
      },
      "source": [
        "Much of the code is inspired by or taken from Aurelien Geron's excellent book \"Hands-On Machine Learning with Scikit-Learn and TensorFlow\" and its corresponding jupyter notebooks https://github.com/ageron/handson-ml2. \n",
        "\n",
        "Section 2 draws upon Jenkinson, Bijsterbosch, Chappell, & Winkler's \"Short introduction to the General Linear Model for Neuroimaging\" https://www.fmrib.ox.ac.uk/primers/appendices/glm.pdf.\n",
        "\n",
        "Section 3.1 is adapted from Jason Brownlee's blog on machine learning https://machinelearningmastery.com/train-final-machine-learning-model/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2NTTq5RhJWj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "2_neural_nets_for_neuroimaging_data_with_keras_v2.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}